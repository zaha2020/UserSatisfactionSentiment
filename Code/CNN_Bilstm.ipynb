{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "-zI1pLbHwfJx",
        "outputId": "f14d0106-4c70-49a4-fd0e-326f52d40abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/roshan-research/hazm.git\n",
            "  Cloning https://github.com/roshan-research/hazm.git to /tmp/pip-req-build-oplwcj0_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/roshan-research/hazm.git /tmp/pip-req-build-oplwcj0_\n",
            "  Resolved https://github.com/roshan-research/hazm.git to commit 410e5f3e98bc267648b1f8c9e024c15c49c514b7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm==0.9.4)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flashtext<3.0,>=2.7 (from hazm==0.9.4)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm==0.9.4) (4.3.2)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm==0.9.4) (3.8.1)\n",
            "Collecting numpy==1.24.3 (from hazm==0.9.4)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm==0.9.4)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm==0.9.4) (1.2.2)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm==0.9.4)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm==0.9.4) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm==0.9.4) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm==0.9.4) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm==0.9.4) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm==0.9.4) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm==0.9.4) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm==0.9.4) (4.66.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm==0.9.4) (3.2.0)\n",
            "Building wheels for collected packages: hazm, flashtext\n",
            "  Building wheel for hazm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hazm: filename=hazm-0.9.4-py3-none-any.whl size=882187 sha256=15782b5926e7ada6594bcfa7273e671192fb7d19d2f0d9f7bc5ae79c889912f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ovvby9ca/wheels/55/89/b4/56e12f36fffd749eba685e3c99fbb1d69a9029a8e0dac2a0f1\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9297 sha256=2f3904011bd5e5f4ff5bf9cb2f064f7a55ecba26b1baf5809e2b7d3decddeff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built hazm flashtext\n",
            "Installing collected packages: python-crfsuite, flashtext, pybind11, numpy, fasttext-wheel, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.9.4 numpy-1.24.3 pybind11-2.11.1 python-crfsuite-0.9.9\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install git+https://github.com/roshan-research/hazm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ms2ld7R4whHA"
      },
      "outputs": [],
      "source": [
        "!pip install -q hazm\n",
        "!pip install -q scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fPNsSw0twhDq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "from __future__ import unicode_literals\n",
        "from hazm import Normalizer, word_tokenize\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.utils import class_weight\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AJ_1S7XqwhAx"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/train.csv',encoding ='utf-8')\n",
        "test_df = pd.read_csv('/content/test.csv',encoding ='utf-8')\n",
        "train_related_df = pd.read_csv('/content/train_related.csv',encoding ='utf-8')\n",
        "test_related_df= pd.read_csv('/content/test_related.csv',encoding ='utf-8')\n",
        "train_related_specific_df = pd.read_csv('/content/train_related_specific.csv',encoding ='utf-8')\n",
        "test_related_specific_df = pd.read_csv('/content/test_related_specific.csv',encoding ='utf-8')\n",
        "\n",
        "\n",
        "data_classes_= [-1,0,1]\n",
        "d=dict(zip(data_classes_, range(0,3)))\n",
        "train_related_df['InRelationship']=train_related_df['InRelationship'].map(d, na_action='ignore')\n",
        "test_related_df['InRelationship']=test_related_df['InRelationship'].map(d, na_action='ignore')\n",
        "\n",
        "\n",
        "\n",
        "train_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
        "test_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
        "train_related_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
        "test_related_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
        "train_related_specific_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
        "test_related_specific_df.drop(['Unnamed: 0'], axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LGT3Tcpzwg-Q"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "  tokens = word_tokenize(text) # tokenize\n",
        "  # without_stopwords = [token for token in tokens if token not in stopwords] # remove stopwords\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xs789m4Ux9GQ"
      },
      "outputs": [],
      "source": [
        "train_df['tokens'] = train_df['Record_text'].apply(lambda t: get_tokens(t))\n",
        "test_df['tokens'] = test_df['Record_text'].apply(lambda t: get_tokens(t))\n",
        "train_related_df['tokens'] = train_related_df['Record_text'].apply(lambda t: get_tokens(t))\n",
        "test_related_df['tokens'] = test_related_df['Record_text'].apply(lambda t: get_tokens(t))\n",
        "train_related_specific_df['tokens'] = train_related_specific_df['Record_text'].apply(lambda t: get_tokens(t))\n",
        "test_related_specific_df['tokens'] = test_related_specific_df['Record_text'].apply(lambda t: get_tokens(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "gPZ6HcAEx9C5",
        "outputId": "36fdf2d0-4428-402d-8c08-93640c1d5381"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f6ae82a-0546-4ad8-85ac-9a31100890e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Record_text</th>\n",
              "      <th>InRelationship</th>\n",
              "      <th>General_comment_binary</th>\n",
              "      <th>General_comment</th>\n",
              "      <th>Specific_comment_binary</th>\n",
              "      <th>Specific_comment</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Relevance</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>تو سال جدید تصمیم گرفتم دور دوستای متاهلم رو خ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>بد</td>\n",
              "      <td>1</td>\n",
              "      <td>[تو, سال, جدید, تصمیم, گرفتم, دور, دوستای, متا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[PLEADING_][PLEADING_][PLEADING_][PLEADING_][P...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>خوب</td>\n",
              "      <td>1</td>\n",
              "      <td>[[, PLEADING_, ], [, PLEADING_, ], [, PLEADING...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اقا دو روزه کاملا اینجا توسط همگان شدم، امروز ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[اقا, دو, روزه, کاملا, اینجا, توسط, همگان, شدم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الکی به خانمم گفتم من قبل تو با یه خانم   ساله...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[الکی, به, خانمم, گفتم, من, قبل, تو, با, یه, خ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>دلم میخواد اینو بفرستم به پارتنر سابقم و دوبار...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>سابق</td>\n",
              "      <td>1</td>\n",
              "      <td>[دلم, میخواد, اینو, بفرستم, به, پارتنر, سابقم,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>برای گفتن از شب های اخر برای این شانس بی مروتِ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[برای, گفتن, از, شب, های, اخر, برای, این, شانس...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>افرین به شما که روی شوهر تون غیرت و تعصب دارید...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>افرین غیرت</td>\n",
              "      <td>1</td>\n",
              "      <td>[افرین, به, شما, که, روی, شوهر, تون, غیرت, و, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>یه بار دوست دخترم پریود بود، واسش خوراکی گرفتم...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>خوب</td>\n",
              "      <td>1</td>\n",
              "      <td>[یه, بار, دوست, دخترم, پریود, بود, ،, واسش, خو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>موقع خدمت خیلی راحت سُفره دلشونو پیشت پهن میکر...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>بد</td>\n",
              "      <td>1</td>\n",
              "      <td>[موقع, خدمت, خیلی, راحت, سُفره, دلشونو, پیشت, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f6ae82a-0546-4ad8-85ac-9a31100890e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f6ae82a-0546-4ad8-85ac-9a31100890e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f6ae82a-0546-4ad8-85ac-9a31100890e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-537a4a1d-dd95-4fb8-a6ac-088c8c131dd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-537a4a1d-dd95-4fb8-a6ac-088c8c131dd3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-537a4a1d-dd95-4fb8-a6ac-088c8c131dd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         Record_text  InRelationship  \\\n",
              "1  تو سال جدید تصمیم گرفتم دور دوستای متاهلم رو خ...               0   \n",
              "2  [PLEADING_][PLEADING_][PLEADING_][PLEADING_][P...               2   \n",
              "3  اقا دو روزه کاملا اینجا توسط همگان شدم، امروز ...               2   \n",
              "4  الکی به خانمم گفتم من قبل تو با یه خانم   ساله...               2   \n",
              "5  دلم میخواد اینو بفرستم به پارتنر سابقم و دوبار...               1   \n",
              "6  برای گفتن از شب های اخر برای این شانس بی مروتِ...               0   \n",
              "7  افرین به شما که روی شوهر تون غیرت و تعصب دارید...               2   \n",
              "8  یه بار دوست دخترم پریود بود، واسش خوراکی گرفتم...               2   \n",
              "9  موقع خدمت خیلی راحت سُفره دلشونو پیشت پهن میکر...               0   \n",
              "\n",
              "   General_comment_binary  General_comment Specific_comment_binary  \\\n",
              "1                       1                1                     0.0   \n",
              "2                       1                0                     1.0   \n",
              "3                       1                2                     1.0   \n",
              "4                       1                2                     1.0   \n",
              "5                       1                1                     1.0   \n",
              "6                       1                2                     0.0   \n",
              "7                       1                0                     1.0   \n",
              "8                       1                0                     1.0   \n",
              "9                       1                1                     0.0   \n",
              "\n",
              "   Specific_comment     Comment  Relevance  \\\n",
              "1                 3          بد          1   \n",
              "2                 0         خوب          1   \n",
              "3                 2       کامنت          1   \n",
              "4                 2       کامنت          1   \n",
              "5                 1        سابق          1   \n",
              "6                 3       کامنت          1   \n",
              "7                 0  افرین غیرت          1   \n",
              "8                 0         خوب          1   \n",
              "9                 3          بد          1   \n",
              "\n",
              "                                              tokens  \n",
              "1  [تو, سال, جدید, تصمیم, گرفتم, دور, دوستای, متا...  \n",
              "2  [[, PLEADING_, ], [, PLEADING_, ], [, PLEADING...  \n",
              "3  [اقا, دو, روزه, کاملا, اینجا, توسط, همگان, شدم...  \n",
              "4  [الکی, به, خانمم, گفتم, من, قبل, تو, با, یه, خ...  \n",
              "5  [دلم, میخواد, اینو, بفرستم, به, پارتنر, سابقم,...  \n",
              "6  [برای, گفتن, از, شب, های, اخر, برای, این, شانس...  \n",
              "7  [افرین, به, شما, که, روی, شوهر, تون, غیرت, و, ...  \n",
              "8  [یه, بار, دوست, دخترم, پریود, بود, ،, واسش, خو...  \n",
              "9  [موقع, خدمت, خیلی, راحت, سُفره, دلشونو, پیشت, ...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_related_df[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "pdamiUrtx9AW",
        "outputId": "ecebcd14-05ac-46df-c682-06d1497c2a5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1cd0837b-1774-497a-aa48-7df86f7ff613\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Record_text</th>\n",
              "      <th>InRelationship</th>\n",
              "      <th>General_comment_binary</th>\n",
              "      <th>General_comment</th>\n",
              "      <th>Specific_comment_binary</th>\n",
              "      <th>Specific_comment</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Relevance</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>داشتیم چیزکیک میخوردیم گفتم حال میکنی دوست دخت...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[داشتیم, چیزکیک, میخوردیم, گفتم, حال, میکنی, د...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[PLEADING_][PLEADING_][PLEADING_][PLEADING_][P...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>خوب</td>\n",
              "      <td>1</td>\n",
              "      <td>[[, PLEADING_, ], [, PLEADING_, ], [, PLEADING...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اقا دو روزه کاملا اینجا توسط همگان شدم، امروز ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[اقا, دو, روزه, کاملا, اینجا, توسط, همگان, شدم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>الکی به خانمم گفتم من قبل تو با یه خانم   ساله...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[الکی, به, خانمم, گفتم, من, قبل, تو, با, یه, خ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>دلم میخواد اینو بفرستم به پارتنر سابقم و دوبار...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>سابق</td>\n",
              "      <td>1</td>\n",
              "      <td>[دلم, میخواد, اینو, بفرستم, به, پارتنر, سابقم,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2448</th>\n",
              "      <td>دقیقا، چند روز پیش که ازش رد شدیم، همسرم همینو...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>تجربه خوب</td>\n",
              "      <td>1</td>\n",
              "      <td>[دقیقا, ،, چند, روز, پیش, که, ازش, رد, شدیم, ،...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2449</th>\n",
              "      <td>این بابامهههههه میخواد منو به فرزندی قبول کنه ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>نظری نداره</td>\n",
              "      <td>1</td>\n",
              "      <td>[این, بابامهههههه, میخواد, منو, به, فرزندی, قب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2450</th>\n",
              "      <td>شما چه پولدارید میرید تنیس با همسر جان :))))) ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>مقایسه</td>\n",
              "      <td>1</td>\n",
              "      <td>[شما, چه, پولدارید, میرید, تنیس, با, همسر, جان...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2451</th>\n",
              "      <td>با اینکه در تاریخ  / /  بزرگترین و کوچکترین فر...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>نظری نداره</td>\n",
              "      <td>1</td>\n",
              "      <td>[با, اینکه, در, تاریخ, /, /, بزرگترین, و, کوچک...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>پام عفونت کرده باید انتی بیوتیک بخورم ولی برای...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>کامنت</td>\n",
              "      <td>1</td>\n",
              "      <td>[پام, عفونت, کرده, باید, انتی, بیوتیک, بخورم, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2453 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cd0837b-1774-497a-aa48-7df86f7ff613')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cd0837b-1774-497a-aa48-7df86f7ff613 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cd0837b-1774-497a-aa48-7df86f7ff613');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4dc5f0c5-dd78-454b-8705-3229f864a2c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dc5f0c5-dd78-454b-8705-3229f864a2c3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4dc5f0c5-dd78-454b-8705-3229f864a2c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            Record_text  InRelationship  \\\n",
              "0     داشتیم چیزکیک میخوردیم گفتم حال میکنی دوست دخت...               1   \n",
              "1     [PLEADING_][PLEADING_][PLEADING_][PLEADING_][P...               1   \n",
              "2     اقا دو روزه کاملا اینجا توسط همگان شدم، امروز ...               1   \n",
              "3     الکی به خانمم گفتم من قبل تو با یه خانم   ساله...               1   \n",
              "4     دلم میخواد اینو بفرستم به پارتنر سابقم و دوبار...               0   \n",
              "...                                                 ...             ...   \n",
              "2448  دقیقا، چند روز پیش که ازش رد شدیم، همسرم همینو...               1   \n",
              "2449  این بابامهههههه میخواد منو به فرزندی قبول کنه ...               1   \n",
              "2450  شما چه پولدارید میرید تنیس با همسر جان :))))) ...               1   \n",
              "2451  با اینکه در تاریخ  / /  بزرگترین و کوچکترین فر...               1   \n",
              "2452  پام عفونت کرده باید انتی بیوتیک بخورم ولی برای...               1   \n",
              "\n",
              "      General_comment_binary  General_comment Specific_comment_binary  \\\n",
              "0                          1                0                     1.0   \n",
              "1                          1                0                     1.0   \n",
              "2                          1                2                     1.0   \n",
              "3                          1                2                     1.0   \n",
              "4                          1                1                     1.0   \n",
              "...                      ...              ...                     ...   \n",
              "2448                       1                0                     1.0   \n",
              "2449                       1                2                     1.0   \n",
              "2450                       1                1                     1.0   \n",
              "2451                       1                2                     1.0   \n",
              "2452                       1                1                     1.0   \n",
              "\n",
              "      Specific_comment     Comment  Relevance  \\\n",
              "0                    0       کامنت          1   \n",
              "1                    0         خوب          1   \n",
              "2                    2       کامنت          1   \n",
              "3                    2       کامنت          1   \n",
              "4                    1        سابق          1   \n",
              "...                ...         ...        ...   \n",
              "2448                 0   تجربه خوب          1   \n",
              "2449                 2  نظری نداره          1   \n",
              "2450                 1      مقایسه          1   \n",
              "2451                 2  نظری نداره          1   \n",
              "2452                 1       کامنت          1   \n",
              "\n",
              "                                                 tokens  \n",
              "0     [داشتیم, چیزکیک, میخوردیم, گفتم, حال, میکنی, د...  \n",
              "1     [[, PLEADING_, ], [, PLEADING_, ], [, PLEADING...  \n",
              "2     [اقا, دو, روزه, کاملا, اینجا, توسط, همگان, شدم...  \n",
              "3     [الکی, به, خانمم, گفتم, من, قبل, تو, با, یه, خ...  \n",
              "4     [دلم, میخواد, اینو, بفرستم, به, پارتنر, سابقم,...  \n",
              "...                                                 ...  \n",
              "2448  [دقیقا, ،, چند, روز, پیش, که, ازش, رد, شدیم, ،...  \n",
              "2449  [این, بابامهههههه, میخواد, منو, به, فرزندی, قب...  \n",
              "2450  [شما, چه, پولدارید, میرید, تنیس, با, همسر, جان...  \n",
              "2451  [با, اینکه, در, تاریخ, /, /, بزرگترین, و, کوچک...  \n",
              "2452  [پام, عفونت, کرده, باید, انتی, بیوتیک, بخورم, ...  \n",
              "\n",
              "[2453 rows x 9 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_related_specific_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoW710Brx89r",
        "outputId": "d0f922bf-fb42-4a98-a575-ade871550bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data after tokenization\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['موقع',\n",
              " 'خدمت',\n",
              " 'خیلی',\n",
              " 'راحت',\n",
              " 'سُفره',\n",
              " 'دلشونو',\n",
              " 'پیشت',\n",
              " 'پهن',\n",
              " 'میکردن',\n",
              " '.',\n",
              " 'یکیشون',\n",
              " 'خواستگاری',\n",
              " 'رفته_بود',\n",
              " 'و',\n",
              " 'گفته',\n",
              " 'بودن',\n",
              " 'باید',\n",
              " 'اول',\n",
              " 'خدمت',\n",
              " 'بری',\n",
              " '.',\n",
              " 'حالا',\n",
              " 'اومده',\n",
              " 'بود',\n",
              " 'خدمت',\n",
              " 'و',\n",
              " 'بعد',\n",
              " 'چندماه',\n",
              " '،',\n",
              " 'اونا',\n",
              " 'دختره',\n",
              " 'رو',\n",
              " 'شوهر',\n",
              " 'داده',\n",
              " 'بودن',\n",
              " '.',\n",
              " 'شب',\n",
              " 'ها',\n",
              " 'من',\n",
              " 'بیشتر',\n",
              " 'پُست',\n",
              " 'میدادم',\n",
              " 'تا',\n",
              " 'جوون',\n",
              " 'های',\n",
              " '،',\n",
              " 'ساله',\n",
              " 'تاصبح',\n",
              " 'تریاک',\n",
              " 'وشیشه',\n",
              " 'و…بکشن',\n",
              " '.',\n",
              " 'یکی',\n",
              " 'لیسانس',\n",
              " 'بود',\n",
              " 'وحالا',\n",
              " 'باید',\n",
              " 'اوامر']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Data after tokenization')\n",
        "train_related_df['tokens'][9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz4oHjMpyilT"
      },
      "source": [
        "# Create vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B-nGcAA31ywH"
      },
      "outputs": [],
      "source": [
        "train_words = list(set([word for i in range(len(train_df)) for word in train_df['tokens'][i]]))\n",
        "test_words = list(set([word for i in range(len(test_df)) for word in test_df['tokens'][i]]))\n",
        "\n",
        "train_related_words = list(set([word for i in range(len(train_related_df)) for word in train_related_df['tokens'][i]]))\n",
        "test_related_words = list(set([word for i in range(len(test_related_df)) for word in test_related_df['tokens'][i]]))\n",
        "\n",
        "train_related_specific_words = list(set([word for i in range(len(train_related_specific_df)) for word in train_related_specific_df['tokens'][i]]))\n",
        "test_related_specific_words = list(set([word for i in range(len(test_related_specific_df)) for word in test_related_specific_df['tokens'][i]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dz7YN0mk0udr"
      },
      "outputs": [],
      "source": [
        "unique_words_ = list(set(train_words + test_words))\n",
        "unique_words_related_words= list(set(train_related_words + test_related_words))\n",
        "unique_words_specific_words= list(set(train_related_specific_words + test_related_specific_words))\n",
        "\n",
        "\n",
        "\n",
        "unique_words=[unique_words_, unique_words_related_words, unique_words_specific_words]\n",
        "unknown_idx=[1,1,1]\n",
        "padding_idx=[0,0,0]\n",
        "\n",
        "unique_words_new = []\n",
        "for i in range(3):\n",
        "    unique_words_new.append( ['<padding_word>', '<unknown_word>'] + unique_words[i]) # .append('<unknown_word>') #add unknown token to vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f50W_vvh-Kes",
        "outputId": "0f1745b1-f396-470a-c456-1e5e9932aaaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of tokens in vocabulary 31994\n",
            "number of tokens in vocabulary 20239\n",
            "number of tokens in vocabulary 11104\n"
          ]
        }
      ],
      "source": [
        "for k in unique_words_new:\n",
        "    if k==unique_words_new[0]:\n",
        "       word2idx = {}\n",
        "       idx2word = {}\n",
        "       word2idx_related = {}\n",
        "       idx2word_related= {}\n",
        "       word2idx_specific= {}\n",
        "       idx2word_specific= {}\n",
        "       for i,w in enumerate(k):\n",
        "           word2idx[w] = i\n",
        "           idx2word[i] = w\n",
        "    elif k==unique_words_new[1]:\n",
        "       for i,w in enumerate(k):\n",
        "            word2idx_related[w] = i\n",
        "            idx2word_related[i] = w\n",
        "    else:\n",
        "       for i,w in enumerate(k):\n",
        "            word2idx_specific[w] = i\n",
        "            idx2word_specific[i] = w\n",
        "\n",
        "       print(f'number of tokens in vocabulary {len(word2idx)}')\n",
        "       print(f'number of tokens in vocabulary {len(word2idx_related)}')\n",
        "       print(f'number of tokens in vocabulary {len(word2idx_specific)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23K6BLgix4ZC",
        "outputId": "71086ab8-0618-4479-8988-9ee05c43521c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20238"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.max(list(word2idx_related.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I0VQK-DR-KcF"
      },
      "outputs": [],
      "source": [
        "final_data = train_df['tokens'].values\n",
        "final_test_data = test_df['tokens'].values\n",
        "\n",
        "final_train_related_data = train_related_df['tokens'].values\n",
        "final_test_related_data = test_related_df['tokens'].values\n",
        "\n",
        "final_train_specific_data = train_related_specific_df['tokens'].values\n",
        "final_test_specific_data = test_related_specific_df['tokens'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9tfYatGGcFw"
      },
      "source": [
        "## Convert sentences to numerical vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KK6hlFiT-KZe"
      },
      "outputs": [],
      "source": [
        "train_words_vec = [[word2idx[item] if item in word2idx else unknown_idx[0] for item in i] for i in final_data[:]]\n",
        "\n",
        "train_related_words_vec = [[word2idx_related[item] if item in word2idx_related else unknown_idx[1] for item in i] for i in final_train_related_data[:]]\n",
        "\n",
        "train_specific_words_vec = [[word2idx_specific[item] if item in word2idx_specific else unknown_idx[2] for item in i] for i in final_train_specific_data[:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bduU_cqfGkk1"
      },
      "outputs": [],
      "source": [
        "test_words_vec = [[word2idx[item] if item in word2idx else unknown_idx[0] for item in i] for i in final_test_data[:]]\n",
        "\n",
        "test_related_words_vec = [[word2idx_related[item] if item in word2idx_related else unknown_idx[1] for item in i] for i in final_test_related_data[:]]\n",
        "\n",
        "test_specific_words_vec = [[word2idx_specific[item] if item in word2idx_specific else unknown_idx[2] for item in i] for i in final_test_specific_data[:]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "duWS8YZZGkiY"
      },
      "outputs": [],
      "source": [
        "train_labels = train_df['Relevance'].values[:]\n",
        "test_labels = test_df['Relevance'].values[:]\n",
        "\n",
        "train_related_labels = train_related_df['General_comment'].values[:]\n",
        "test_related_labels = test_related_df['General_comment'].values[:]\n",
        "\n",
        "train_related_InRelationship_labels = train_related_df['InRelationship'].values[:]\n",
        "test_related_InRelationship_labels = test_related_df['InRelationship'].values[:]\n",
        "\n",
        "\n",
        "train_specific_labels = train_related_specific_df['Specific_comment'].values[:]\n",
        "test_specific_labels = test_related_specific_df['Specific_comment'].values[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ClZNz_vIxUS",
        "outputId": "f6b14f74-fd2c-46c6-b305-2eafa92f3fc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.6253527486172255, 1: 7.021546261089988, 2: 0.7946069994262766}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_labels),\n",
        "                                        y = train_labels\n",
        "                                    )\n",
        "\n",
        "class_weights_related = class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_related_labels),\n",
        "                                        y = train_related_labels\n",
        "                                    )\n",
        "\n",
        "weights = class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_related_InRelationship_labels),\n",
        "                                        y = train_related_InRelationship_labels\n",
        "                                    )\n",
        "class_weights_InRelationship_related=dict(enumerate(weights, 0))\n",
        "\n",
        "class_weights_specific = class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_specific_labels),\n",
        "                                        y = train_specific_labels\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(train_labels), class_weights))\n",
        "class_weights_related = dict(zip(np.unique(train_related_labels), class_weights_related))\n",
        "class_weights_specific = dict(zip(np.unique(train_specific_labels), class_weights_specific))\n",
        "\n",
        "class_weights_InRelationship_related"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km6e7f8GKRJt"
      },
      "source": [
        "# Create Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KmLuZZZeKcts"
      },
      "outputs": [],
      "source": [
        "# Function to handle padding in each batch of data\n",
        "def pad_collate(batch):\n",
        "  (xx, yy) = zip(*batch)\n",
        "  x_lens = [len(x) for x in xx]\n",
        "\n",
        "  xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
        "\n",
        "  return xx_pad, yy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1ak6eo5hK-ep"
      },
      "outputs": [],
      "source": [
        "train_data = [[torch.tensor(train_words_vec[i]), torch.tensor([train_labels[i]])] for i in range(len(train_words_vec))]\n",
        "\n",
        "train_related_data = [[torch.tensor(train_related_words_vec[i]), torch.tensor([train_related_labels[i]])] for i in range(len(train_related_words_vec))]\n",
        "\n",
        "train_related_InRelationship_data = [[torch.tensor(train_related_words_vec[i]), torch.tensor([train_related_InRelationship_labels[i]])] for i in range(len(train_related_words_vec))]\n",
        "\n",
        "train_specific_data = [[torch.tensor(train_specific_words_vec[i]), torch.tensor([train_specific_labels[i]])] for i in range(len(train_specific_words_vec))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_-xd6ehpTUoI"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_data = [[torch.tensor(test_words_vec[i]), torch.tensor([test_labels[i]])] for i in range(len(test_words_vec))]\n",
        "\n",
        "test_related_data = [[torch.tensor(test_related_words_vec[i]), torch.tensor([test_related_labels[i]])] for i in range(len(test_related_words_vec))]\n",
        "\n",
        "test_related_InRelationship_data = [[torch.tensor(test_related_words_vec[i]), torch.tensor([test_related_InRelationship_labels[i]])] for i in range(len(test_related_words_vec))]\n",
        "\n",
        "test_specific_data = [[torch.tensor(test_specific_words_vec[i]), torch.tensor([test_specific_labels[i]])] for i in range(len(test_specific_words_vec))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lThWCooyK-Yo"
      },
      "outputs": [],
      "source": [
        "train_set, val_set = torch.utils.data.random_split(train_data, [10771, 85])\n",
        "train_related_set, val_related_set = torch.utils.data.random_split(train_related_data, [5455, 85])\n",
        "train_related_InRelationship_set, val_related_InRelationship_set = torch.utils.data.random_split(train_related_InRelationship_data, [5455, 85])\n",
        "train_specific_set, val_specific_set = torch.utils.data.random_split(train_specific_data, [2368, 85])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wN6SkQFHK-VX"
      },
      "outputs": [],
      "source": [
        "data_loader_Trianset = DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "data_loader_Val = DataLoader(\n",
        "    dataset=val_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "data_loader_Relatedset = DataLoader(\n",
        "    dataset=train_related_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "data_loader_Valrelated = DataLoader(\n",
        "    dataset=val_related_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "\n",
        "data_loader_InRelationship_Relatedset = DataLoader(\n",
        "    dataset=train_related_InRelationship_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "data_loader_InRelationship_Valrelated = DataLoader(\n",
        "    dataset=val_related_InRelationship_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "data_loader_Specific_set = DataLoader(\n",
        "    dataset=train_specific_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "\n",
        "data_loader_Valspecific = DataLoader(\n",
        "    dataset=val_specific_set,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biOuM3d4UeaR"
      },
      "source": [
        "# Test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TmWY0rGKR0s6"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "test_loader_Related = DataLoader(\n",
        "    dataset=test_related_data,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "test_loader_InRelationship_Related = DataLoader(\n",
        "    dataset=test_related_InRelationship_data,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "test_loader_Specific = DataLoader(\n",
        "    dataset=test_specific_data,\n",
        "    batch_size=512,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo88sFUUVJ3j"
      },
      "source": [
        "# Define a random embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PK9dzkE_Uqsx"
      },
      "outputs": [],
      "source": [
        "embedding_matrixs = np.random.normal(loc=0.0, scale=0.12, size=(len(word2idx),128))\n",
        "embedding_matrixs_related = np.random.normal(loc=0.0, scale=0.12, size=(len(word2idx_related),128))\n",
        "embedding_matrixs_specific = np.random.normal(loc=0.0, scale=0.12, size=(len(word2idx_specific),128))\n",
        "# embedding_matrixs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYbsodgsgz1i"
      },
      "source": [
        "\n",
        "\n",
        "# CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "15q2PpqjUqpR"
      },
      "outputs": [],
      "source": [
        "class CNN_Model_TEXT(nn.Module):\n",
        "    def __init__(self,max_features, embed_size, embedding_matrix, num_classes,num_filters):\n",
        "        super(CNN_Model_TEXT, self).__init__()\n",
        "        filter_sizes = [3, 5, 7]\n",
        "        num_filters = num_filters\n",
        "        n_classes = num_classes\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        # print(x.size())\n",
        "        x = x.unsqueeze(1)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        logit = self.softmax(self.fc1(x))\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRSNUwaHVVGA"
      },
      "source": [
        "# Use GPU for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkk0yFTjVUNG",
        "outputId": "f1deaa29-9a51-4d1f-d5bd-1a1fc93481ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OYpSiYYXUqmv"
      },
      "outputs": [],
      "source": [
        "embed_size = embedding_matrixs.shape[1]\n",
        "vocab_size = embedding_matrixs.shape[0]\n",
        "num_classes = 2\n",
        "num_filters=36\n",
        "\n",
        "model = CNN_Model_TEXT(vocab_size, embed_size, embedding_matrixs,num_classes,num_filters)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # weighted negative log likelihood loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms-b_anKgt9-"
      },
      "source": [
        "# Training_loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3nJ0qyTYV-Lx"
      },
      "outputs": [],
      "source": [
        "def training_loop(e, model,data_loader,valid_loader,criterion,optimizer):\n",
        "  import time\n",
        "  start_time = time.time()\n",
        "  num_epochs = e\n",
        "  train_loss = []\n",
        "  validation_loss = []\n",
        "  train_acc=[]\n",
        "  val_acc = []\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc=0\n",
        "    # Training loop\n",
        "    for idx, (sentence, label) in enumerate(iter(data_loader)):\n",
        "      # print(\"idx\", idx)\n",
        "      sentence, label = sentence.to(device),torch.tensor(list(label)).to(device)\n",
        "      # print(sentence)\n",
        "      # Put the model into the training mode\n",
        "      model.train()\n",
        "      # Zero out any previously calculated gradients\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward\n",
        "      outputs = model(sentence)\n",
        "      # print(outputs)\n",
        "      # Calculate the batch loss and accuracy\n",
        "      pred = torch.argmax(outputs, dim=1)\n",
        "      running_acc += sum(pred==label).item() /len(label)\n",
        "      loss = criterion(outputs, label)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update the parameters in the optimize.\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # print(loss.item())\n",
        "    # validation\n",
        "    model.eval()\n",
        "    running_loss_valid = 0.0\n",
        "    running_acc_valid = 0.0\n",
        "    for jdx, (sentence, label) in enumerate(iter(valid_loader)):\n",
        "      sentence, label = sentence.to(device),torch.tensor(list(label)).to(device)\n",
        "      # Feed forward\n",
        "      outputs = model(sentence)\n",
        "      loss = criterion(outputs, label)\n",
        "      # Calculate the batch loss and accuracy\n",
        "      running_loss_valid += loss.item()\n",
        "      pred = torch.argmax(outputs, dim=1)\n",
        "      running_acc_valid += sum(pred==label).item()/len(label)\n",
        "    # print training and validation info\n",
        "    print(f'epoch: {epoch+1} -  train loss: {running_loss / (idx+1)} - validation loss: {running_loss_valid/(jdx+1)} - train acc = {running_acc/(idx+1)} - validation acc = {running_acc_valid/(jdx+1)}')\n",
        "    train_loss.append(running_loss / (idx+1))\n",
        "    validation_loss.append(running_loss_valid/(jdx+1))\n",
        "    train_acc.append(running_acc/(idx+1))\n",
        "    val_acc.append(running_acc_valid/(jdx+1))\n",
        "    # saving model\n",
        "    torch.save(model.cpu().state_dict(), 'final_model.pth')\n",
        "    model.to(device)\n",
        "\n",
        "  running_time = time.time()-start_time\n",
        "  print(f'training Finished in {running_time} seconds')\n",
        "  return train_loss,validation_loss,train_acc,val_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGp-KQ6R0q_"
      },
      "source": [
        "## Relevance_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQUYSdKcYchj",
        "outputId": "4dea7cba-2317-4f87-be93-f0742ac9e1fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 0.6881066804582422 - validation loss: 0.6700348854064941 - train acc = 0.5358197517942584 - validation acc = 0.6235294117647059\n",
            "epoch: 2 -  train loss: 0.6611770499836315 - validation loss: 0.6325376629829407 - train acc = 0.6295650792464115 - validation acc = 0.6941176470588235\n",
            "epoch: 3 -  train loss: 0.6263849112120542 - validation loss: 0.5798651576042175 - train acc = 0.6531848086124402 - validation acc = 0.6941176470588235\n",
            "epoch: 4 -  train loss: 0.5733518194068562 - validation loss: 0.52817302942276 - train acc = 0.7169884494617225 - validation acc = 0.7294117647058823\n",
            "epoch: 5 -  train loss: 0.5124842998656359 - validation loss: 0.47984951734542847 - train acc = 0.7612000971889952 - validation acc = 0.7647058823529411\n",
            "epoch: 6 -  train loss: 0.4607725969769738 - validation loss: 0.47267451882362366 - train acc = 0.793436004784689 - validation acc = 0.7764705882352941\n",
            "epoch: 7 -  train loss: 0.393866010687568 - validation loss: 0.4476630687713623 - train acc = 0.836745850777512 - validation acc = 0.8\n",
            "epoch: 8 -  train loss: 0.3494235195896842 - validation loss: 0.4610164761543274 - train acc = 0.8664866178229665 - validation acc = 0.788235294117647\n",
            "epoch: 9 -  train loss: 0.28667411411350424 - validation loss: 0.4575637876987457 - train acc = 0.8986197293660286 - validation acc = 0.788235294117647\n",
            "epoch: 10 -  train loss: 0.2414696907455271 - validation loss: 0.4521959125995636 - train acc = 0.9190434360047847 - validation acc = 0.8117647058823529\n",
            "training Finished in 34.666709661483765 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop(10,model,data_loader_Trianset,data_loader_Val,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBl-whTA0TQE",
        "outputId": "50e00844-4574-4214-cdb1-489d5bce2d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 0.6898037306964397 - validation loss: 0.6824984550476074 - train acc = 0.5404296875 - validation acc = 0.5882352941176471\n",
            "epoch: 2 -  train loss: 0.6608770303428173 - validation loss: 0.6684602499008179 - train acc = 0.6118896484375 - validation acc = 0.5529411764705883\n",
            "epoch: 3 -  train loss: 0.6344353891909122 - validation loss: 0.6276310682296753 - train acc = 0.64638671875 - validation acc = 0.6588235294117647\n",
            "epoch: 4 -  train loss: 0.5828554034233093 - validation loss: 0.594811201095581 - train acc = 0.7085205078125 - validation acc = 0.7058823529411765\n",
            "epoch: 5 -  train loss: 0.5410730894654989 - validation loss: 0.5656232833862305 - train acc = 0.744775390625 - validation acc = 0.7176470588235294\n",
            "epoch: 6 -  train loss: 0.4890931583940983 - validation loss: 0.533439040184021 - train acc = 0.7818115234375 - validation acc = 0.7294117647058823\n",
            "epoch: 7 -  train loss: 0.43466234765946865 - validation loss: 0.5161467790603638 - train acc = 0.8173828125 - validation acc = 0.7647058823529411\n",
            "epoch: 8 -  train loss: 0.3543036989867687 - validation loss: 0.5304832458496094 - train acc = 0.8654052734375 - validation acc = 0.7529411764705882\n",
            "epoch: 9 -  train loss: 0.28521566186100245 - validation loss: 0.5292832851409912 - train acc = 0.9018310546875 - validation acc = 0.7529411764705882\n",
            "epoch: 10 -  train loss: 0.22083529829978943 - validation loss: 0.5511664748191833 - train acc = 0.9354736328125 - validation acc = 0.7647058823529411\n",
            "training Finished in 18.912700653076172 seconds\n"
          ]
        }
      ],
      "source": [
        "#train_loss,validation_loss,train_acc,val_acc=training_loop(10,model,data_loader_Trianset,data_loader_Val,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xDmYmCIjhsZ_"
      },
      "outputs": [],
      "source": [
        "def plot(train_loss,validation_loss,train_acc,val_acc):\n",
        "    fig = plt.figure(figsize=(15,6))\n",
        "    fig.add_subplot(121)\n",
        "    plt.plot(train_acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.legend([\"train accuracy\", \"validation accuracy\"])\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.grid()\n",
        "\n",
        "\n",
        "    # Plot the Loss Curves\n",
        "    fig.add_subplot(122)\n",
        "    plt.plot(train_loss)\n",
        "    plt.plot(validation_loss)\n",
        "    plt.legend([\"train loss\", \"validation loss\"])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.grid()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "LdhJILqnVyGP",
        "outputId": "96c20839-49dd-44bf-c502-9db3e9755d90"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(train_loss,validation_loss,train_acc,val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "53vaBRbqVx4S"
      },
      "outputs": [],
      "source": [
        "def Evaluate(model,test_loader):\n",
        "  y_pred= []\n",
        "  y_label=[]\n",
        "  with torch.no_grad():\n",
        "    for jdx, (sentence, label) in enumerate(iter(test_loader)):\n",
        "      sentence, label = sentence.to(device),torch.tensor(list(label)).to(device)\n",
        "      # Feed forward\n",
        "      outputs = model(sentence)\n",
        "      pred = torch.argmax(outputs, dim=1)\n",
        "      for i in range(len(label)):\n",
        "        y_pred.append(pred[i].item())\n",
        "        y_label.append(label[i].item())\n",
        "  print(classification_report(y_label, y_pred))\n",
        "  print(f'''Accuracy: {round(accuracy_score(y_label, y_pred, normalize=True),6)}\n",
        "  \\nPrecision:{round(precision_score(y_label, y_pred, average='macro'),6)}\n",
        "  \\nRecall: {round(recall_score(y_label, y_pred, average='macro'),6)}\n",
        "  \\nF1 score: {round(f1_score(y_label, y_pred, average='macro'),6)}''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqw5gZPPYqdz",
        "outputId": "2bd284e0-2d01-412b-b23e-e3d96fa1838a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73      1156\n",
            "           1       0.75      0.73      0.74      1227\n",
            "\n",
            "    accuracy                           0.73      2383\n",
            "   macro avg       0.73      0.73      0.73      2383\n",
            "weighted avg       0.74      0.73      0.73      2383\n",
            "\n",
            "Accuracy: 0.734788\n",
            "  \n",
            "Precision:0.734724\n",
            "  \n",
            "Recall: 0.734928\n",
            "  \n",
            "F1 score: 0.73471\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ8itU_-VZxc"
      },
      "source": [
        "# General_comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaOSGDJWq2zI",
        "outputId": "181ee4ed-ed51-48cf-8e6b-115e7ff57f50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 1.4844587352625938, 1: 0.7064524356031625, 2: 1.0978993261989696}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_weights_related"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "VvVorUXBUqe0"
      },
      "outputs": [],
      "source": [
        "embed_size_ = embedding_matrixs_related.shape[1]\n",
        "vocab_size_ = embedding_matrixs_related.shape[0]\n",
        "num_classes_ = 3\n",
        "num_filters=36\n",
        "\n",
        "model_General_comment = CNN_Model_TEXT(vocab_size_, embed_size_, embedding_matrixs_related,num_classes_,num_filters)\n",
        "\n",
        "model_General_comment.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights_related.values())).float().to(device))\n",
        "optimizer = optim.Adam(model_General_comment.parameters(), lr=0.0001, weight_decay=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC0ivsH5YvaL",
        "outputId": "a5654a67-d1c9-44af-981f-815ea5cc462f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.0990063927390359 - validation loss: 1.0966688394546509 - train acc = 0.23561524762550884 - validation acc = 0.24705882352941178\n",
            "epoch: 2 -  train loss: 1.094402248209173 - validation loss: 1.0960386991500854 - train acc = 0.2789428214043419 - validation acc = 0.2823529411764706\n",
            "epoch: 3 -  train loss: 1.0920469869266858 - validation loss: 1.0954488515853882 - train acc = 0.3231311482360923 - validation acc = 0.3411764705882353\n",
            "epoch: 4 -  train loss: 1.0904136029156772 - validation loss: 1.0950366258621216 - train acc = 0.3621401161804613 - validation acc = 0.43529411764705883\n",
            "epoch: 5 -  train loss: 1.08802668614821 - validation loss: 1.0946193933486938 - train acc = 0.40595318860244234 - validation acc = 0.4235294117647059\n",
            "epoch: 6 -  train loss: 1.0871787938204678 - validation loss: 1.0946801900863647 - train acc = 0.4343893105495251 - validation acc = 0.4235294117647059\n",
            "epoch: 7 -  train loss: 1.0858971747485073 - validation loss: 1.094414472579956 - train acc = 0.4682189196065129 - validation acc = 0.4235294117647059\n",
            "epoch: 8 -  train loss: 1.0842252644625576 - validation loss: 1.0944770574569702 - train acc = 0.48682899423337855 - validation acc = 0.43529411764705883\n",
            "epoch: 9 -  train loss: 1.0831144397908992 - validation loss: 1.0938363075256348 - train acc = 0.49455775101763905 - validation acc = 0.4\n",
            "epoch: 10 -  train loss: 1.0824811892075972 - validation loss: 1.093847393989563 - train acc = 0.4937134285956581 - validation acc = 0.4235294117647059\n",
            "epoch: 11 -  train loss: 1.0818543109026821 - validation loss: 1.0934925079345703 - train acc = 0.4961992240502035 - validation acc = 0.43529411764705883\n",
            "epoch: 12 -  train loss: 1.0810764919627796 - validation loss: 1.0931659936904907 - train acc = 0.502142342265943 - validation acc = 0.4588235294117647\n",
            "epoch: 13 -  train loss: 1.080345869064331 - validation loss: 1.0927796363830566 - train acc = 0.49952934192673 - validation acc = 0.4470588235294118\n",
            "epoch: 14 -  train loss: 1.079278122295033 - validation loss: 1.0922237634658813 - train acc = 0.5014623261533243 - validation acc = 0.4470588235294118\n",
            "epoch: 15 -  train loss: 1.0781882025978782 - validation loss: 1.0920779705047607 - train acc = 0.5045210736092266 - validation acc = 0.4588235294117647\n",
            "epoch: 16 -  train loss: 1.0774474035609851 - validation loss: 1.0919435024261475 - train acc = 0.5092546853799186 - validation acc = 0.47058823529411764\n",
            "epoch: 17 -  train loss: 1.0767428441481157 - validation loss: 1.0914758443832397 - train acc = 0.5121560167910448 - validation acc = 0.4470588235294118\n",
            "epoch: 18 -  train loss: 1.075603810223666 - validation loss: 1.0912280082702637 - train acc = 0.507402264246947 - validation acc = 0.4588235294117647\n",
            "epoch: 19 -  train loss: 1.075276797468012 - validation loss: 1.0906860828399658 - train acc = 0.5106751399253731 - validation acc = 0.4588235294117647\n",
            "epoch: 20 -  train loss: 1.0747761726379395 - validation loss: 1.0903773307800293 - train acc = 0.508239696404342 - validation acc = 0.4470588235294118\n",
            "epoch: 21 -  train loss: 1.0732929489829324 - validation loss: 1.090775966644287 - train acc = 0.5103772684871098 - validation acc = 0.4823529411764706\n",
            "epoch: 22 -  train loss: 1.0731719082052058 - validation loss: 1.0906496047973633 - train acc = 0.5106852103120759 - validation acc = 0.47058823529411764\n",
            "epoch: 23 -  train loss: 1.072279767556624 - validation loss: 1.0901994705200195 - train acc = 0.5151511618046133 - validation acc = 0.47058823529411764\n",
            "epoch: 24 -  train loss: 1.0717526782642712 - validation loss: 1.0899971723556519 - train acc = 0.5103603078358209 - validation acc = 0.47058823529411764\n",
            "epoch: 25 -  train loss: 1.0714890523390337 - validation loss: 1.090104579925537 - train acc = 0.49868501950474897 - validation acc = 0.47058823529411764\n",
            "training Finished in 35.45814371109009 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop(25,model_General_comment,data_loader_Relatedset,data_loader_Valrelated,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8-IWy2bZR8r",
        "outputId": "27eaf153-84cb-445c-a892-b7b03dec7adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.33      0.31       269\n",
            "           1       0.53      0.69      0.60       575\n",
            "           2       0.40      0.18      0.25       381\n",
            "\n",
            "    accuracy                           0.45      1225\n",
            "   macro avg       0.41      0.40      0.38      1225\n",
            "weighted avg       0.44      0.45      0.43      1225\n",
            "\n",
            "Accuracy: 0.451429\n",
            "  \n",
            "Precision:0.405874\n",
            "  \n",
            "Recall: 0.398683\n",
            "  \n",
            "F1 score: 0.384203\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_General_comment,test_loader_Related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0t4UCX8AQ3_"
      },
      "source": [
        "## InRelationship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "De9maKlw_UoR"
      },
      "outputs": [],
      "source": [
        "embed_size_ = embedding_matrixs_related.shape[1]\n",
        "vocab_size_ = embedding_matrixs_related.shape[0]\n",
        "num_classes_ = 3\n",
        "num_filters=36\n",
        "\n",
        "model_InRelationship = CNN_Model_TEXT(vocab_size_, embed_size_, embedding_matrixs_related,num_classes_,num_filters)\n",
        "\n",
        "model_InRelationship.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights_InRelationship_related.values())).float().to(device))\n",
        "optimizer = optim.Adam(model_InRelationship.parameters(), lr=0.001, weight_decay=0.00005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMRlOO2SZXbk",
        "outputId": "f7a03e86-36b5-45cb-a0e7-217c52ee047d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.0920855023644187 - validation loss: 1.0782760381698608 - train acc = 0.3916018275101764 - validation acc = 0.6470588235294118\n",
            "epoch: 2 -  train loss: 1.0599451390179722 - validation loss: 1.0598160028457642 - train acc = 0.5444278960312077 - validation acc = 0.5411764705882353\n",
            "epoch: 3 -  train loss: 1.0234812172976406 - validation loss: 1.0255147218704224 - train acc = 0.6791839806648575 - validation acc = 0.6352941176470588\n",
            "epoch: 4 -  train loss: 0.9740511775016785 - validation loss: 0.983102023601532 - train acc = 0.6917936948778833 - validation acc = 0.5882352941176471\n",
            "epoch: 5 -  train loss: 0.8984736691821705 - validation loss: 0.9137494564056396 - train acc = 0.7393624915196745 - validation acc = 0.7058823529411765\n",
            "epoch: 6 -  train loss: 0.8043193979696794 - validation loss: 0.8469043970108032 - train acc = 0.7865189323270013 - validation acc = 0.7294117647058823\n",
            "epoch: 7 -  train loss: 0.6991830197247592 - validation loss: 0.783989429473877 - train acc = 0.8043753180122116 - validation acc = 0.8\n",
            "epoch: 8 -  train loss: 0.5897271904078397 - validation loss: 0.7215008735656738 - train acc = 0.8460343877204884 - validation acc = 0.8\n",
            "epoch: 9 -  train loss: 0.4753152104941281 - validation loss: 0.6831598877906799 - train acc = 0.8731703697421981 - validation acc = 0.8\n",
            "epoch: 10 -  train loss: 0.37712547183036804 - validation loss: 0.6436878442764282 - train acc = 0.9045947464382632 - validation acc = 0.8705882352941177\n",
            "epoch: 11 -  train loss: 0.2971684255383231 - validation loss: 0.6708285212516785 - train acc = 0.9226954715061059 - validation acc = 0.8470588235294118\n",
            "epoch: 12 -  train loss: 0.2309898097406734 - validation loss: 0.686969518661499 - train acc = 0.9409806436567165 - validation acc = 0.8588235294117647\n",
            "epoch: 13 -  train loss: 0.17947862229563974 - validation loss: 0.6916009187698364 - train acc = 0.9568669436906376 - validation acc = 0.8588235294117647\n",
            "epoch: 14 -  train loss: 0.14353394305164163 - validation loss: 0.7511622905731201 - train acc = 0.9679056775780189 - validation acc = 0.8588235294117647\n",
            "epoch: 15 -  train loss: 0.11511668562889099 - validation loss: 0.755123496055603 - train acc = 0.9762307072591588 - validation acc = 0.8235294117647058\n",
            "epoch: 16 -  train loss: 0.09352449598637494 - validation loss: 0.8213634490966797 - train acc = 0.9799694708276797 - validation acc = 0.8352941176470589\n",
            "epoch: 17 -  train loss: 0.07522428238933737 - validation loss: 0.8380113244056702 - train acc = 0.9868305842944369 - validation acc = 0.8352941176470589\n",
            "epoch: 18 -  train loss: 0.06358458508144725 - validation loss: 0.873319685459137 - train acc = 0.9902979774423337 - validation acc = 0.8470588235294118\n",
            "epoch: 19 -  train loss: 0.053958879614418205 - validation loss: 0.9205709099769592 - train acc = 0.9924387296472184 - validation acc = 0.8470588235294118\n",
            "epoch: 20 -  train loss: 0.044964071701873436 - validation loss: 0.9375372529029846 - train acc = 0.9946732954545454 - validation acc = 0.8352941176470589\n",
            "training Finished in 28.44079351425171 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop(20,model_InRelationship,data_loader_InRelationship_Relatedset,data_loader_InRelationship_Valrelated,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpeXpphRZg1H",
        "outputId": "b2ecf8bb-9359-4c7e-bd3f-7e809d096522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.80       650\n",
            "           1       0.35      0.16      0.22        51\n",
            "           2       0.73      0.82      0.77       524\n",
            "\n",
            "    accuracy                           0.77      1225\n",
            "   macro avg       0.64      0.59      0.60      1225\n",
            "weighted avg       0.77      0.77      0.77      1225\n",
            "\n",
            "Accuracy: 0.773061\n",
            "  \n",
            "Precision:0.636193\n",
            "  \n",
            "Recall: 0.587097\n",
            "  \n",
            "F1 score: 0.598409\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_InRelationship,test_loader_InRelationship_Related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVYGpEbVgKk"
      },
      "source": [
        "# Specific_comment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDxnFxl1IVFk",
        "outputId": "30da0004-0abe-4439-95bf-993c4057d150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 1.0259305729820158, 1: 1.0233625365039634, 2: 0.9541034616880592}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_weights_specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kcecmYtXQAZC"
      },
      "outputs": [],
      "source": [
        "embed_size__ = embedding_matrixs_specific.shape[1]\n",
        "vocab_size__ = embedding_matrixs_specific.shape[0]\n",
        "num_classes__ = 3\n",
        "num_filters=36\n",
        "\n",
        "model_Specific_comment = CNN_Model_TEXT(vocab_size__, embed_size__, embedding_matrixs_specific,num_classes__,num_filters)\n",
        "\n",
        "model_Specific_comment.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0,weight=torch.tensor(list(class_weights_specific.values())).float().to(device)) # weighted negative log likelihood loss\n",
        "optimizer = optim.Adam(model_Specific_comment.parameters(),lr=0.001, weight_decay=0.00005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLgoUR1vZkpE",
        "outputId": "31350b08-dcbc-4d51-e481-85203cf2b0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.0015202283859252 - validation loss: 0.8992960453033447 - train acc = 0.34734375 - validation acc = 0.3411764705882353\n",
            "epoch: 2 -  train loss: 0.8119017362594605 - validation loss: 0.7804434299468994 - train acc = 0.35164062500000004 - validation acc = 0.3411764705882353\n",
            "epoch: 3 -  train loss: 0.709375512599945 - validation loss: 0.7284325957298279 - train acc = 0.408515625 - validation acc = 0.3058823529411765\n",
            "epoch: 4 -  train loss: 0.6748887419700622 - validation loss: 0.7175107598304749 - train acc = 0.40765624999999994 - validation acc = 0.32941176470588235\n",
            "epoch: 5 -  train loss: 0.6543228149414062 - validation loss: 0.7202281951904297 - train acc = 0.451953125 - validation acc = 0.3058823529411765\n",
            "epoch: 6 -  train loss: 0.6380778431892395 - validation loss: 0.7151602506637573 - train acc = 0.473125 - validation acc = 0.32941176470588235\n",
            "epoch: 7 -  train loss: 0.6184780836105347 - validation loss: 0.7159066796302795 - train acc = 0.48851562499999995 - validation acc = 0.32941176470588235\n",
            "epoch: 8 -  train loss: 0.6004260897636413 - validation loss: 0.7175606489181519 - train acc = 0.5190625 - validation acc = 0.3058823529411765\n",
            "epoch: 9 -  train loss: 0.5773558139801025 - validation loss: 0.7179218530654907 - train acc = 0.549453125 - validation acc = 0.35294117647058826\n",
            "epoch: 10 -  train loss: 0.5537351608276367 - validation loss: 0.719316840171814 - train acc = 0.558203125 - validation acc = 0.32941176470588235\n",
            "epoch: 11 -  train loss: 0.526262617111206 - validation loss: 0.7213574051856995 - train acc = 0.582734375 - validation acc = 0.3411764705882353\n",
            "epoch: 12 -  train loss: 0.4896931231021881 - validation loss: 0.7235046029090881 - train acc = 0.601640625 - validation acc = 0.3411764705882353\n",
            "epoch: 13 -  train loss: 0.4554961800575256 - validation loss: 0.7249603867530823 - train acc = 0.612265625 - validation acc = 0.32941176470588235\n",
            "epoch: 14 -  train loss: 0.41237530708312986 - validation loss: 0.7252029180526733 - train acc = 0.6284375 - validation acc = 0.35294117647058826\n",
            "epoch: 15 -  train loss: 0.36571375727653505 - validation loss: 0.725049614906311 - train acc = 0.640703125 - validation acc = 0.35294117647058826\n",
            "epoch: 16 -  train loss: 0.3231703996658325 - validation loss: 0.7277655601501465 - train acc = 0.641328125 - validation acc = 0.36470588235294116\n",
            "epoch: 17 -  train loss: 0.27285551726818086 - validation loss: 0.7325094938278198 - train acc = 0.657734375 - validation acc = 0.4\n",
            "epoch: 18 -  train loss: 0.23157444298267366 - validation loss: 0.7390865683555603 - train acc = 0.6590625 - validation acc = 0.3764705882352941\n",
            "epoch: 19 -  train loss: 0.1883009195327759 - validation loss: 0.7514078617095947 - train acc = 0.6622656250000001 - validation acc = 0.38823529411764707\n",
            "epoch: 20 -  train loss: 0.15396228730678557 - validation loss: 0.7691126465797424 - train acc = 0.665078125 - validation acc = 0.36470588235294116\n",
            "epoch: 21 -  train loss: 0.12639198452234268 - validation loss: 0.7902429699897766 - train acc = 0.664140625 - validation acc = 0.36470588235294116\n",
            "epoch: 22 -  train loss: 0.10261304676532745 - validation loss: 0.8084802627563477 - train acc = 0.66921875 - validation acc = 0.4117647058823529\n",
            "epoch: 23 -  train loss: 0.08147549629211426 - validation loss: 0.8273187279701233 - train acc = 0.6653125 - validation acc = 0.38823529411764707\n",
            "epoch: 24 -  train loss: 0.06645267903804779 - validation loss: 0.8497329354286194 - train acc = 0.6700781250000001 - validation acc = 0.38823529411764707\n",
            "epoch: 25 -  train loss: 0.056431439518928525 - validation loss: 0.8701648116111755 - train acc = 0.67109375 - validation acc = 0.4\n",
            "epoch: 26 -  train loss: 0.04790573790669441 - validation loss: 0.8922207355499268 - train acc = 0.6739843750000001 - validation acc = 0.38823529411764707\n",
            "epoch: 27 -  train loss: 0.03954823985695839 - validation loss: 0.9139877557754517 - train acc = 0.67125 - validation acc = 0.38823529411764707\n",
            "epoch: 28 -  train loss: 0.03219344168901443 - validation loss: 0.9359028935432434 - train acc = 0.668984375 - validation acc = 0.4\n",
            "epoch: 29 -  train loss: 0.029340209439396858 - validation loss: 0.9590350985527039 - train acc = 0.67234375 - validation acc = 0.38823529411764707\n",
            "epoch: 30 -  train loss: 0.02608969770371914 - validation loss: 0.9776692986488342 - train acc = 0.668671875 - validation acc = 0.38823529411764707\n",
            "epoch: 31 -  train loss: 0.02334216795861721 - validation loss: 0.9957849979400635 - train acc = 0.6753125 - validation acc = 0.38823529411764707\n",
            "epoch: 32 -  train loss: 0.020754850655794143 - validation loss: 1.0110206604003906 - train acc = 0.67390625 - validation acc = 0.4\n",
            "epoch: 33 -  train loss: 0.02016828451305628 - validation loss: 1.0266376733779907 - train acc = 0.668203125 - validation acc = 0.4\n",
            "epoch: 34 -  train loss: 0.017362468317151068 - validation loss: 1.0427024364471436 - train acc = 0.6728125 - validation acc = 0.4\n",
            "epoch: 35 -  train loss: 0.016624733246862887 - validation loss: 1.0563918352127075 - train acc = 0.676640625 - validation acc = 0.4\n",
            "epoch: 36 -  train loss: 0.015694790333509446 - validation loss: 1.0680415630340576 - train acc = 0.67421875 - validation acc = 0.4235294117647059\n",
            "epoch: 37 -  train loss: 0.014353804476559161 - validation loss: 1.0782673358917236 - train acc = 0.6771874999999999 - validation acc = 0.4235294117647059\n",
            "epoch: 38 -  train loss: 0.014047801867127419 - validation loss: 1.090695858001709 - train acc = 0.6732812499999999 - validation acc = 0.4235294117647059\n",
            "epoch: 39 -  train loss: 0.012167282216250897 - validation loss: 1.1017005443572998 - train acc = 0.6759375000000001 - validation acc = 0.4235294117647059\n",
            "epoch: 40 -  train loss: 0.012345182150602341 - validation loss: 1.1112849712371826 - train acc = 0.673046875 - validation acc = 0.4235294117647059\n",
            "epoch: 41 -  train loss: 0.01180705539882183 - validation loss: 1.1218879222869873 - train acc = 0.673828125 - validation acc = 0.4235294117647059\n",
            "epoch: 42 -  train loss: 0.011669011041522025 - validation loss: 1.1306792497634888 - train acc = 0.670625 - validation acc = 0.4235294117647059\n",
            "epoch: 43 -  train loss: 0.010999047756195068 - validation loss: 1.136398196220398 - train acc = 0.6753125 - validation acc = 0.4235294117647059\n",
            "epoch: 44 -  train loss: 0.009102975018322468 - validation loss: 1.1434422731399536 - train acc = 0.6759375000000001 - validation acc = 0.4235294117647059\n",
            "epoch: 45 -  train loss: 0.00946151725947857 - validation loss: 1.1549081802368164 - train acc = 0.67640625 - validation acc = 0.4235294117647059\n",
            "epoch: 46 -  train loss: 0.00944477105513215 - validation loss: 1.1642334461212158 - train acc = 0.674765625 - validation acc = 0.4235294117647059\n",
            "epoch: 47 -  train loss: 0.009808070957660675 - validation loss: 1.175315499305725 - train acc = 0.67515625 - validation acc = 0.4235294117647059\n",
            "epoch: 48 -  train loss: 0.008663526456803083 - validation loss: 1.179979681968689 - train acc = 0.675546875 - validation acc = 0.43529411764705883\n",
            "epoch: 49 -  train loss: 0.008494174666702747 - validation loss: 1.1844673156738281 - train acc = 0.67421875 - validation acc = 0.43529411764705883\n",
            "epoch: 50 -  train loss: 0.007882018480449915 - validation loss: 1.1899266242980957 - train acc = 0.6713281249999999 - validation acc = 0.43529411764705883\n",
            "training Finished in 31.044147729873657 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss_,validation_loss_,train_acc_,val_acc_=training_loop(50,model_Specific_comment,data_loader_Specific_set,data_loader_Valspecific,criterion,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wExuaeeLaIHS",
        "outputId": "3d46d531-1817-4d4f-f4ae-eedba0b8af95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       171\n",
            "           1       0.42      0.56      0.48       181\n",
            "           2       0.44      0.69      0.54       195\n",
            "\n",
            "    accuracy                           0.43       547\n",
            "   macro avg       0.29      0.42      0.34       547\n",
            "weighted avg       0.29      0.43      0.35       547\n",
            "\n",
            "Accuracy: 0.429616\n",
            "  \n",
            "Precision:0.285476\n",
            "  \n",
            "Recall: 0.415064\n",
            "  \n",
            "F1 score: 0.33783\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_Specific_comment,test_loader_Specific)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vXr83aiyCqO"
      },
      "source": [
        "--------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IkylPlqhz1V"
      },
      "source": [
        "# Bilstm\n",
        "\n",
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "AA_7nhVDJCD4"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self,max_features, embed_size, embedding_matrix, num_classes, hidden_size):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        drp = 0.5\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size*4 , 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(drp)\n",
        "        self.out = nn.Linear(64, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
        "\n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        avg_pool = torch.mean(h_lstm, 1)\n",
        "        max_pool, _ = torch.max(h_lstm, 1)\n",
        "        #print(\"avg_pool\", avg_pool.size())\n",
        "        #print(\"max_pool\", max_pool.size())\n",
        "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1_4FK1Z_sibY"
      },
      "outputs": [],
      "source": [
        "def training_loop_(e, model,data_loader,valid_loader,criterion,optimizer):\n",
        "# number of epochs to train the model\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    n_epochs = e\n",
        "   # test_loss_min = np.Inf # track change in validation loss\n",
        "    train_acc=[]\n",
        "    val_acc = []\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        train_loss = 0.0\n",
        "        test_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        running_acc=0\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            target = torch.tensor([[t] for t in target])\n",
        "            data, target = data.to(device),torch.tensor(list(target)).to(device)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            y_pred = torch.round(torch.sigmoid(output))\n",
        "            output =  torch.argmax(output, dim=1).float()\n",
        "\n",
        "            running_acc += torch.round((((output == target).sum().float() /len(target))) * 100)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        running_acc_valid = 0.0\n",
        "        for j,(data, target) in enumerate(valid_loader):\n",
        "            # target = target.unsqueeze(1)\n",
        "            target = torch.tensor([[t] for t in target])\n",
        "            data, target = data.to(device),torch.tensor(list(target)).to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            output =  torch.argmax(output, dim=1).float()\n",
        "            # y_pred_tag = torch.round(torch.sigmoid(output))\n",
        "            running_acc_valid += torch.round((((output == target).sum().float() /len(target))) * 100)\n",
        "            # update average validation loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        print(f'epoch: {epoch+1} -  train loss: {train_loss / (i+1)} - validation loss: {test_loss/(j+1)} - train acc = {running_acc/(i+1)} - validation acc = {running_acc_valid/(j+1)}')\n",
        "\n",
        "        train_loss = train_loss/len(data_loader)\n",
        "        test_loss = test_loss/len(valid_loader)\n",
        "        train_acc.append(running_acc/(i+1))\n",
        "        val_acc.append(running_acc_valid/(j+1))\n",
        "        torch.save(model.cpu().state_dict(), 'final_model.pth')\n",
        "        model.to(device)\n",
        "    running_time = time.time()-start_time\n",
        "    print(f'training Finished in {running_time} seconds')\n",
        "    return train_loss,test_loss,train_acc,val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwMMOkNLRp6R"
      },
      "source": [
        "## Relevance_Bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fZHzxdL0JCBJ"
      },
      "outputs": [],
      "source": [
        "embed_size = embedding_matrixs.shape[1]\n",
        "vocab_size = embedding_matrixs.shape[0]\n",
        "num_classes = 2\n",
        "\n",
        "model_Relevance_Bilstm = BiLSTM(vocab_size, embed_size, embedding_matrixs,num_classes,20)\n",
        "model_Relevance_Bilstm.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model_Relevance_Bilstm.parameters(), lr=0.001, weight_decay=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkvITXfMaPS0",
        "outputId": "b4769a93-92ff-460f-a83d-e5dccdf553b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 0.692989240993153 - validation loss: 0.692179262638092 - train acc = 51.72727584838867 - validation acc = 54.0\n",
            "epoch: 2 -  train loss: 0.6935492672703483 - validation loss: 0.6906390190124512 - train acc = 50.5 - validation acc = 54.0\n",
            "epoch: 3 -  train loss: 0.6922976239161058 - validation loss: 0.6905774474143982 - train acc = 51.1363639831543 - validation acc = 54.0\n",
            "epoch: 4 -  train loss: 0.691797985271974 - validation loss: 0.6883116960525513 - train acc = 52.36363983154297 - validation acc = 54.0\n",
            "epoch: 5 -  train loss: 0.6902504021471197 - validation loss: 0.6866044402122498 - train acc = 52.590911865234375 - validation acc = 60.0\n",
            "epoch: 6 -  train loss: 0.6845888116142966 - validation loss: 0.6752890348434448 - train acc = 56.681819915771484 - validation acc = 62.0\n",
            "epoch: 7 -  train loss: 0.6677752462300387 - validation loss: 0.6381511092185974 - train acc = 61.81818389892578 - validation acc = 65.0\n",
            "epoch: 8 -  train loss: 0.6326286115429618 - validation loss: 0.5708093643188477 - train acc = 64.63636779785156 - validation acc = 69.0\n",
            "epoch: 9 -  train loss: 0.5696251378817991 - validation loss: 0.5025140047073364 - train acc = 71.81818389892578 - validation acc = 75.0\n",
            "epoch: 10 -  train loss: 0.4953673170371489 - validation loss: 0.4697748124599457 - train acc = 78.09091186523438 - validation acc = 79.0\n",
            "training Finished in 6.270839691162109 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop_(10,model_Relevance_Bilstm,data_loader_Trianset,data_loader_Val,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUvaaLpoald0",
        "outputId": "65c3a993-2dd2-4518-f22e-bcb3af85bafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.74      0.71      1156\n",
            "           1       0.73      0.69      0.71      1227\n",
            "\n",
            "    accuracy                           0.71      2383\n",
            "   macro avg       0.71      0.71      0.71      2383\n",
            "weighted avg       0.71      0.71      0.71      2383\n",
            "\n",
            "Accuracy: 0.711288\n",
            "  \n",
            "Precision:0.712141\n",
            "  \n",
            "Recall: 0.712033\n",
            "  \n",
            "F1 score: 0.711284\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_Relevance_Bilstm,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S94HNNFMRmLO"
      },
      "source": [
        "## General_comment_Bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cwYv8U-T5le7"
      },
      "outputs": [],
      "source": [
        "embed_size_ = embedding_matrixs_related.shape[1]\n",
        "vocab_size_ = embedding_matrixs_related.shape[0]\n",
        "num_classes_ = 3\n",
        "\n",
        "model_General_comment_Bilstm = BiLSTM(vocab_size_, embed_size_, embedding_matrixs_related,num_classes_,10)\n",
        "\n",
        "\n",
        "model_General_comment_Bilstm.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights_related.values())).float().to(device))\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model_General_comment_Bilstm.parameters(), lr=0.0001, weight_decay=0.000005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKs_0A12ao8D",
        "outputId": "47ee09ac-e183-4068-eb1e-6e9f09fb176c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.1017352884465998 - validation loss: 1.1048487424850464 - train acc = 40.181819915771484 - validation acc = 44.0\n",
            "epoch: 2 -  train loss: 1.102652289650657 - validation loss: 1.1036230325698853 - train acc = 38.0 - validation acc = 42.0\n",
            "epoch: 3 -  train loss: 1.1002997918562456 - validation loss: 1.1027157306671143 - train acc = 38.0 - validation acc = 40.0\n",
            "epoch: 4 -  train loss: 1.098748044534163 - validation loss: 1.1019070148468018 - train acc = 37.3636360168457 - validation acc = 41.0\n",
            "epoch: 5 -  train loss: 1.097134525125677 - validation loss: 1.1013667583465576 - train acc = 38.181819915771484 - validation acc = 41.0\n",
            "epoch: 6 -  train loss: 1.0971573157743975 - validation loss: 1.1008861064910889 - train acc = 38.3636360168457 - validation acc = 41.0\n",
            "epoch: 7 -  train loss: 1.0961969332261519 - validation loss: 1.1004972457885742 - train acc = 39.181819915771484 - validation acc = 42.0\n",
            "epoch: 8 -  train loss: 1.0964945879849521 - validation loss: 1.1001529693603516 - train acc = 36.6363639831543 - validation acc = 40.0\n",
            "epoch: 9 -  train loss: 1.0933515158566562 - validation loss: 1.0999127626419067 - train acc = 39.45454788208008 - validation acc = 36.0\n",
            "epoch: 10 -  train loss: 1.0945946194908835 - validation loss: 1.099643588066101 - train acc = 37.81818389892578 - validation acc = 36.0\n",
            "epoch: 11 -  train loss: 1.0941599932583896 - validation loss: 1.0994819402694702 - train acc = 38.181819915771484 - validation acc = 36.0\n",
            "epoch: 12 -  train loss: 1.0936824083328247 - validation loss: 1.099515676498413 - train acc = 39.090911865234375 - validation acc = 36.0\n",
            "epoch: 13 -  train loss: 1.0927461060610684 - validation loss: 1.099504828453064 - train acc = 39.6363639831543 - validation acc = 40.0\n",
            "epoch: 14 -  train loss: 1.092722318389199 - validation loss: 1.099483609199524 - train acc = 39.90909194946289 - validation acc = 40.0\n",
            "epoch: 15 -  train loss: 1.0924174785614014 - validation loss: 1.099484920501709 - train acc = 40.6363639831543 - validation acc = 39.0\n",
            "epoch: 16 -  train loss: 1.0913319912823765 - validation loss: 1.099379539489746 - train acc = 40.727272033691406 - validation acc = 38.0\n",
            "epoch: 17 -  train loss: 1.090564651922746 - validation loss: 1.0993576049804688 - train acc = 40.90909194946289 - validation acc = 40.0\n",
            "epoch: 18 -  train loss: 1.0894234505566684 - validation loss: 1.099371314048767 - train acc = 41.181819915771484 - validation acc = 40.0\n",
            "epoch: 19 -  train loss: 1.088310425931757 - validation loss: 1.0993101596832275 - train acc = 42.0 - validation acc = 40.0\n",
            "epoch: 20 -  train loss: 1.0875475948507136 - validation loss: 1.099661946296692 - train acc = 41.3636360168457 - validation acc = 41.0\n",
            "epoch: 21 -  train loss: 1.0862524942918257 - validation loss: 1.0995402336120605 - train acc = 42.90909194946289 - validation acc = 41.0\n",
            "epoch: 22 -  train loss: 1.0846990997141057 - validation loss: 1.099715232849121 - train acc = 44.0 - validation acc = 41.0\n",
            "epoch: 23 -  train loss: 1.084143801168962 - validation loss: 1.0997314453125 - train acc = 43.6363639831543 - validation acc = 40.0\n",
            "epoch: 24 -  train loss: 1.0841575210744685 - validation loss: 1.0998238325119019 - train acc = 44.0 - validation acc = 40.0\n",
            "epoch: 25 -  train loss: 1.0834088217128406 - validation loss: 1.0997484922409058 - train acc = 44.0 - validation acc = 39.0\n",
            "epoch: 26 -  train loss: 1.0804487683556296 - validation loss: 1.0995680093765259 - train acc = 44.54545593261719 - validation acc = 41.0\n",
            "epoch: 27 -  train loss: 1.079087799245661 - validation loss: 1.099433183670044 - train acc = 44.90909194946289 - validation acc = 41.0\n",
            "epoch: 28 -  train loss: 1.077501351183111 - validation loss: 1.0995627641677856 - train acc = 45.181819915771484 - validation acc = 41.0\n",
            "epoch: 29 -  train loss: 1.0777070630680432 - validation loss: 1.0994566679000854 - train acc = 44.81818389892578 - validation acc = 41.0\n",
            "epoch: 30 -  train loss: 1.075186317617243 - validation loss: 1.0995187759399414 - train acc = 46.54545593261719 - validation acc = 41.0\n",
            "epoch: 31 -  train loss: 1.073252255266363 - validation loss: 1.099532961845398 - train acc = 47.0 - validation acc = 41.0\n",
            "epoch: 32 -  train loss: 1.072215351191434 - validation loss: 1.099485158920288 - train acc = 47.6363639831543 - validation acc = 42.0\n",
            "epoch: 33 -  train loss: 1.0692364085804333 - validation loss: 1.0991365909576416 - train acc = 47.45454788208008 - validation acc = 41.0\n",
            "epoch: 34 -  train loss: 1.0682091279463335 - validation loss: 1.0992398262023926 - train acc = 47.090911865234375 - validation acc = 40.0\n",
            "epoch: 35 -  train loss: 1.0655775178562512 - validation loss: 1.0991451740264893 - train acc = 47.72727584838867 - validation acc = 40.0\n",
            "epoch: 36 -  train loss: 1.0624866702339866 - validation loss: 1.098954677581787 - train acc = 48.54545593261719 - validation acc = 40.0\n",
            "epoch: 37 -  train loss: 1.06090201031078 - validation loss: 1.0984464883804321 - train acc = 48.6363639831543 - validation acc = 40.0\n",
            "epoch: 38 -  train loss: 1.0588442087173462 - validation loss: 1.0982868671417236 - train acc = 48.3636360168457 - validation acc = 41.0\n",
            "epoch: 39 -  train loss: 1.0559218796816738 - validation loss: 1.0977879762649536 - train acc = 50.181819915771484 - validation acc = 41.0\n",
            "epoch: 40 -  train loss: 1.0507078929380937 - validation loss: 1.0978535413742065 - train acc = 50.6363639831543 - validation acc = 42.0\n",
            "epoch: 41 -  train loss: 1.0493152791803533 - validation loss: 1.0975043773651123 - train acc = 51.3636360168457 - validation acc = 42.0\n",
            "epoch: 42 -  train loss: 1.0451030297712847 - validation loss: 1.0966770648956299 - train acc = 51.90909194946289 - validation acc = 42.0\n",
            "epoch: 43 -  train loss: 1.0412898388775913 - validation loss: 1.096297025680542 - train acc = 52.54545593261719 - validation acc = 42.0\n",
            "epoch: 44 -  train loss: 1.036603949286721 - validation loss: 1.0950467586517334 - train acc = 54.0 - validation acc = 42.0\n",
            "epoch: 45 -  train loss: 1.032693949612704 - validation loss: 1.0938971042633057 - train acc = 53.54545593261719 - validation acc = 42.0\n",
            "epoch: 46 -  train loss: 1.0290675596757368 - validation loss: 1.0931683778762817 - train acc = 54.36363983154297 - validation acc = 42.0\n",
            "epoch: 47 -  train loss: 1.0234246037223123 - validation loss: 1.0910528898239136 - train acc = 54.81818389892578 - validation acc = 45.0\n",
            "epoch: 48 -  train loss: 1.0174776749177412 - validation loss: 1.0898350477218628 - train acc = 55.90909194946289 - validation acc = 46.0\n",
            "epoch: 49 -  train loss: 1.0108240030028603 - validation loss: 1.088241457939148 - train acc = 57.45454788208008 - validation acc = 46.0\n",
            "epoch: 50 -  train loss: 1.004680801521648 - validation loss: 1.086294412612915 - train acc = 57.54545593261719 - validation acc = 46.0\n",
            "epoch: 51 -  train loss: 0.9965553229505365 - validation loss: 1.083467721939087 - train acc = 58.090911865234375 - validation acc = 46.0\n",
            "epoch: 52 -  train loss: 0.991258523680947 - validation loss: 1.0813024044036865 - train acc = 58.90909194946289 - validation acc = 47.0\n",
            "epoch: 53 -  train loss: 0.980663619258187 - validation loss: 1.078364372253418 - train acc = 60.81818389892578 - validation acc = 47.0\n",
            "epoch: 54 -  train loss: 0.9699004780162465 - validation loss: 1.0747215747833252 - train acc = 61.90909194946289 - validation acc = 47.0\n",
            "epoch: 55 -  train loss: 0.9617103121497415 - validation loss: 1.071853518486023 - train acc = 62.090911865234375 - validation acc = 49.0\n",
            "epoch: 56 -  train loss: 0.9491468559611927 - validation loss: 1.0661587715148926 - train acc = 63.81818389892578 - validation acc = 48.0\n",
            "epoch: 57 -  train loss: 0.9401138099757108 - validation loss: 1.0631539821624756 - train acc = 64.45454406738281 - validation acc = 52.0\n",
            "epoch: 58 -  train loss: 0.9258686249906366 - validation loss: 1.0592169761657715 - train acc = 66.09091186523438 - validation acc = 52.0\n",
            "epoch: 59 -  train loss: 0.9146323691714894 - validation loss: 1.054160475730896 - train acc = 66.2727279663086 - validation acc = 51.0\n",
            "epoch: 60 -  train loss: 0.9003635915842924 - validation loss: 1.0510549545288086 - train acc = 68.7272720336914 - validation acc = 53.0\n",
            "epoch: 61 -  train loss: 0.88749699159102 - validation loss: 1.0445175170898438 - train acc = 69.90909576416016 - validation acc = 53.0\n",
            "epoch: 62 -  train loss: 0.8727434114976362 - validation loss: 1.0400142669677734 - train acc = 70.63636779785156 - validation acc = 53.0\n",
            "epoch: 63 -  train loss: 0.8526160717010498 - validation loss: 1.0352797508239746 - train acc = 72.36363983154297 - validation acc = 53.0\n",
            "epoch: 64 -  train loss: 0.8376535935835405 - validation loss: 1.0320852994918823 - train acc = 73.0 - validation acc = 53.0\n",
            "epoch: 65 -  train loss: 0.8212818124077537 - validation loss: 1.0271193981170654 - train acc = 72.81818389892578 - validation acc = 53.0\n",
            "epoch: 66 -  train loss: 0.8013832785866477 - validation loss: 1.0227611064910889 - train acc = 75.2727279663086 - validation acc = 53.0\n",
            "epoch: 67 -  train loss: 0.7818172194740989 - validation loss: 1.0217995643615723 - train acc = 76.18182373046875 - validation acc = 55.0\n",
            "epoch: 68 -  train loss: 0.7615844065492804 - validation loss: 1.0167526006698608 - train acc = 77.09091186523438 - validation acc = 52.0\n",
            "epoch: 69 -  train loss: 0.7406722523949363 - validation loss: 1.0171281099319458 - train acc = 77.90909576416016 - validation acc = 55.0\n",
            "epoch: 70 -  train loss: 0.7214852950789712 - validation loss: 1.0131189823150635 - train acc = 79.09091186523438 - validation acc = 51.0\n",
            "epoch: 71 -  train loss: 0.700882765379819 - validation loss: 1.013910174369812 - train acc = 78.63636779785156 - validation acc = 52.0\n",
            "epoch: 72 -  train loss: 0.671006977558136 - validation loss: 1.0053571462631226 - train acc = 79.18182373046875 - validation acc = 54.0\n",
            "epoch: 73 -  train loss: 0.6492796540260315 - validation loss: 1.0165138244628906 - train acc = 79.0 - validation acc = 54.0\n",
            "epoch: 74 -  train loss: 0.6290030479431152 - validation loss: 1.0272443294525146 - train acc = 79.63636779785156 - validation acc = 53.0\n",
            "epoch: 75 -  train loss: 0.6018129370429299 - validation loss: 1.0373616218566895 - train acc = 81.45454406738281 - validation acc = 54.0\n",
            "epoch: 76 -  train loss: 0.5804661512374878 - validation loss: 1.0624524354934692 - train acc = 82.54545593261719 - validation acc = 53.0\n",
            "epoch: 77 -  train loss: 0.5663958787918091 - validation loss: 1.084049940109253 - train acc = 82.2727279663086 - validation acc = 53.0\n",
            "epoch: 78 -  train loss: 0.5525727055289529 - validation loss: 1.0783263444900513 - train acc = 82.45455169677734 - validation acc = 53.0\n",
            "epoch: 79 -  train loss: 0.5274440917101774 - validation loss: 1.0976061820983887 - train acc = 82.90909576416016 - validation acc = 56.0\n",
            "epoch: 80 -  train loss: 0.5160668438131158 - validation loss: 1.1339678764343262 - train acc = 84.81818389892578 - validation acc = 53.0\n",
            "training Finished in 15.43476152420044 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop_(80,model_General_comment_Bilstm,data_loader_Relatedset,data_loader_Valrelated,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvzsraCIbMXL",
        "outputId": "83ac5e52-1d7d-408d-f499-d051f50a1db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.32      0.37       269\n",
            "           1       0.62      0.72      0.67       575\n",
            "           2       0.41      0.38      0.39       381\n",
            "\n",
            "    accuracy                           0.53      1225\n",
            "   macro avg       0.49      0.47      0.48      1225\n",
            "weighted avg       0.51      0.53      0.52      1225\n",
            "\n",
            "Accuracy: 0.527347\n",
            "  \n",
            "Precision:0.485688\n",
            "  \n",
            "Recall: 0.474371\n",
            "  \n",
            "F1 score: 0.476072\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_General_comment_Bilstm,test_loader_Related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F0EH0FDRXha"
      },
      "source": [
        "## InRelationship_Bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cmtc-OrpDESS"
      },
      "outputs": [],
      "source": [
        "embed_size_ = embedding_matrixs_related.shape[1]\n",
        "vocab_size_ = embedding_matrixs_related.shape[0]\n",
        "num_classes_ = 3\n",
        "\n",
        "model_InRelationship_Bilstm = BiLSTM(vocab_size_, embed_size_, embedding_matrixs_related,num_classes_,10)\n",
        "\n",
        "\n",
        "model_InRelationship_Bilstm.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights_InRelationship_related.values())).float().to(device))\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model_InRelationship_Bilstm.parameters(),lr=0.0001, weight_decay=0.000005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-xdwTLbRez",
        "outputId": "4ca537ef-cdb4-4e98-9a2c-947044f25fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.1061491749503396 - validation loss: 1.1256499290466309 - train acc = 42.272727966308594 - validation acc = 31.0\n",
            "epoch: 2 -  train loss: 1.1038097143173218 - validation loss: 1.122794270515442 - train acc = 42.090911865234375 - validation acc = 31.0\n",
            "epoch: 3 -  train loss: 1.1022113778374412 - validation loss: 1.1198519468307495 - train acc = 42.272727966308594 - validation acc = 31.0\n",
            "epoch: 4 -  train loss: 1.1032783009789207 - validation loss: 1.1171751022338867 - train acc = 42.272727966308594 - validation acc = 31.0\n",
            "epoch: 5 -  train loss: 1.100009874864058 - validation loss: 1.1146881580352783 - train acc = 42.272727966308594 - validation acc = 31.0\n",
            "epoch: 6 -  train loss: 1.100547432899475 - validation loss: 1.112742304801941 - train acc = 41.90909194946289 - validation acc = 31.0\n",
            "epoch: 7 -  train loss: 1.0985050309788098 - validation loss: 1.1107088327407837 - train acc = 42.272727966308594 - validation acc = 31.0\n",
            "epoch: 8 -  train loss: 1.0965075276114724 - validation loss: 1.1087136268615723 - train acc = 42.45454788208008 - validation acc = 31.0\n",
            "epoch: 9 -  train loss: 1.0967789563265713 - validation loss: 1.1070505380630493 - train acc = 42.45454788208008 - validation acc = 31.0\n",
            "epoch: 10 -  train loss: 1.0966978831724687 - validation loss: 1.1054822206497192 - train acc = 43.0 - validation acc = 31.0\n",
            "epoch: 11 -  train loss: 1.0958623019131748 - validation loss: 1.103995680809021 - train acc = 43.0 - validation acc = 31.0\n",
            "epoch: 12 -  train loss: 1.0944604223424739 - validation loss: 1.102829098701477 - train acc = 43.90909194946289 - validation acc = 31.0\n",
            "epoch: 13 -  train loss: 1.0956112904982134 - validation loss: 1.101460337638855 - train acc = 44.0 - validation acc = 31.0\n",
            "epoch: 14 -  train loss: 1.0938720703125 - validation loss: 1.1003708839416504 - train acc = 45.0 - validation acc = 31.0\n",
            "epoch: 15 -  train loss: 1.0925614400343462 - validation loss: 1.0992070436477661 - train acc = 46.45454788208008 - validation acc = 31.0\n",
            "epoch: 16 -  train loss: 1.0916674353859641 - validation loss: 1.0981091260910034 - train acc = 46.81818389892578 - validation acc = 31.0\n",
            "epoch: 17 -  train loss: 1.08951875296506 - validation loss: 1.0965722799301147 - train acc = 49.0 - validation acc = 34.0\n",
            "epoch: 18 -  train loss: 1.0888866077769885 - validation loss: 1.0951123237609863 - train acc = 50.3636360168457 - validation acc = 42.0\n",
            "epoch: 19 -  train loss: 1.0872910022735596 - validation loss: 1.0930525064468384 - train acc = 50.90909194946289 - validation acc = 46.0\n",
            "epoch: 20 -  train loss: 1.0863965858112683 - validation loss: 1.0913301706314087 - train acc = 53.45454788208008 - validation acc = 49.0\n",
            "epoch: 21 -  train loss: 1.085173639384183 - validation loss: 1.0898171663284302 - train acc = 54.45454788208008 - validation acc = 48.0\n",
            "epoch: 22 -  train loss: 1.083889289335771 - validation loss: 1.0883352756500244 - train acc = 54.45454788208008 - validation acc = 51.0\n",
            "epoch: 23 -  train loss: 1.0829909281297163 - validation loss: 1.0869028568267822 - train acc = 56.72727584838867 - validation acc = 52.0\n",
            "epoch: 24 -  train loss: 1.0809766487641768 - validation loss: 1.0853575468063354 - train acc = 57.181819915771484 - validation acc = 55.0\n",
            "epoch: 25 -  train loss: 1.0780007622458718 - validation loss: 1.0834929943084717 - train acc = 58.272727966308594 - validation acc = 58.0\n",
            "epoch: 26 -  train loss: 1.077165885405107 - validation loss: 1.0817698240280151 - train acc = 58.72727584838867 - validation acc = 59.0\n",
            "epoch: 27 -  train loss: 1.0733485438606956 - validation loss: 1.0798195600509644 - train acc = 60.181819915771484 - validation acc = 59.0\n",
            "epoch: 28 -  train loss: 1.072047938000072 - validation loss: 1.077775239944458 - train acc = 61.45454788208008 - validation acc = 60.0\n",
            "epoch: 29 -  train loss: 1.0708971457047896 - validation loss: 1.0752551555633545 - train acc = 60.45454788208008 - validation acc = 64.0\n",
            "epoch: 30 -  train loss: 1.0670833587646484 - validation loss: 1.073123812675476 - train acc = 62.45454788208008 - validation acc = 64.0\n",
            "epoch: 31 -  train loss: 1.0629346479069104 - validation loss: 1.0705126523971558 - train acc = 63.0 - validation acc = 64.0\n",
            "epoch: 32 -  train loss: 1.0603481422771106 - validation loss: 1.0676889419555664 - train acc = 63.81818389892578 - validation acc = 65.0\n",
            "epoch: 33 -  train loss: 1.0559677860953591 - validation loss: 1.0644975900650024 - train acc = 64.45454406738281 - validation acc = 67.0\n",
            "epoch: 34 -  train loss: 1.0515970208428123 - validation loss: 1.0611103773117065 - train acc = 65.09091186523438 - validation acc = 67.0\n",
            "epoch: 35 -  train loss: 1.049817367033525 - validation loss: 1.0578631162643433 - train acc = 65.2727279663086 - validation acc = 67.0\n",
            "epoch: 36 -  train loss: 1.0450519973581487 - validation loss: 1.0539273023605347 - train acc = 66.7272720336914 - validation acc = 67.0\n",
            "epoch: 37 -  train loss: 1.0413800261237405 - validation loss: 1.0497406721115112 - train acc = 67.18182373046875 - validation acc = 68.0\n",
            "epoch: 38 -  train loss: 1.0331299196590076 - validation loss: 1.045404076576233 - train acc = 69.18182373046875 - validation acc = 69.0\n",
            "epoch: 39 -  train loss: 1.028281493620439 - validation loss: 1.0405919551849365 - train acc = 68.0 - validation acc = 71.0\n",
            "epoch: 40 -  train loss: 1.0247839147394353 - validation loss: 1.0350569486618042 - train acc = 69.2727279663086 - validation acc = 73.0\n",
            "epoch: 41 -  train loss: 1.0194053758274426 - validation loss: 1.0295605659484863 - train acc = 69.0 - validation acc = 74.0\n",
            "epoch: 42 -  train loss: 1.0123522606762974 - validation loss: 1.024479866027832 - train acc = 70.36363983154297 - validation acc = 75.0\n",
            "epoch: 43 -  train loss: 1.00165071812543 - validation loss: 1.0173869132995605 - train acc = 71.36363983154297 - validation acc = 75.0\n",
            "epoch: 44 -  train loss: 0.9965804165059869 - validation loss: 1.0111466646194458 - train acc = 71.90909576416016 - validation acc = 75.0\n",
            "epoch: 45 -  train loss: 0.9874759208072316 - validation loss: 1.0039952993392944 - train acc = 72.81818389892578 - validation acc = 75.0\n",
            "epoch: 46 -  train loss: 0.9784302765672858 - validation loss: 0.9959399700164795 - train acc = 73.54545593261719 - validation acc = 75.0\n",
            "epoch: 47 -  train loss: 0.96897892518477 - validation loss: 0.9880643486976624 - train acc = 74.63636779785156 - validation acc = 75.0\n",
            "epoch: 48 -  train loss: 0.9596156857230447 - validation loss: 0.9788471460342407 - train acc = 75.36363983154297 - validation acc = 76.0\n",
            "epoch: 49 -  train loss: 0.9511075074022467 - validation loss: 0.9708816409111023 - train acc = 76.0 - validation acc = 75.0\n",
            "epoch: 50 -  train loss: 0.9398056702180342 - validation loss: 0.9612944722175598 - train acc = 76.81818389892578 - validation acc = 76.0\n",
            "epoch: 51 -  train loss: 0.9267859242179177 - validation loss: 0.9503339529037476 - train acc = 77.2727279663086 - validation acc = 76.0\n",
            "epoch: 52 -  train loss: 0.9123606302521445 - validation loss: 0.9396783709526062 - train acc = 78.18182373046875 - validation acc = 76.0\n",
            "epoch: 53 -  train loss: 0.9009306322444569 - validation loss: 0.9283459186553955 - train acc = 78.63636779785156 - validation acc = 76.0\n",
            "epoch: 54 -  train loss: 0.8872329159216448 - validation loss: 0.9176933169364929 - train acc = 79.7272720336914 - validation acc = 75.0\n",
            "epoch: 55 -  train loss: 0.874362436207858 - validation loss: 0.9042547345161438 - train acc = 80.63636779785156 - validation acc = 76.0\n",
            "epoch: 56 -  train loss: 0.8581900108944286 - validation loss: 0.8934977650642395 - train acc = 81.09091186523438 - validation acc = 76.0\n",
            "epoch: 57 -  train loss: 0.843523616140539 - validation loss: 0.8801231980323792 - train acc = 81.45454406738281 - validation acc = 75.0\n",
            "epoch: 58 -  train loss: 0.8305406895550814 - validation loss: 0.8661842346191406 - train acc = 82.09091186523438 - validation acc = 76.0\n",
            "epoch: 59 -  train loss: 0.8160600120371039 - validation loss: 0.8534745573997498 - train acc = 82.54545593261719 - validation acc = 76.0\n",
            "epoch: 60 -  train loss: 0.79357741095803 - validation loss: 0.8383887410163879 - train acc = 83.63636779785156 - validation acc = 78.0\n",
            "epoch: 61 -  train loss: 0.7824484814297069 - validation loss: 0.8245387077331543 - train acc = 83.63636779785156 - validation acc = 79.0\n",
            "epoch: 62 -  train loss: 0.7632477716966108 - validation loss: 0.8113036155700684 - train acc = 84.36363983154297 - validation acc = 79.0\n",
            "epoch: 63 -  train loss: 0.7498472766442732 - validation loss: 0.7965789437294006 - train acc = 85.09091186523438 - validation acc = 80.0\n",
            "epoch: 64 -  train loss: 0.7328011718663302 - validation loss: 0.7833663821220398 - train acc = 85.45455169677734 - validation acc = 80.0\n",
            "epoch: 65 -  train loss: 0.7121415951035239 - validation loss: 0.7693120837211609 - train acc = 86.54545593261719 - validation acc = 80.0\n",
            "epoch: 66 -  train loss: 0.6948191577737982 - validation loss: 0.7571680545806885 - train acc = 86.09091186523438 - validation acc = 80.0\n",
            "epoch: 67 -  train loss: 0.6814070343971252 - validation loss: 0.7435165643692017 - train acc = 85.7272720336914 - validation acc = 82.0\n",
            "epoch: 68 -  train loss: 0.6597406701608137 - validation loss: 0.7292914986610413 - train acc = 87.0 - validation acc = 82.0\n",
            "epoch: 69 -  train loss: 0.6405832930044695 - validation loss: 0.7165104746818542 - train acc = 87.63636779785156 - validation acc = 82.0\n",
            "epoch: 70 -  train loss: 0.6194477677345276 - validation loss: 0.6717249751091003 - train acc = 88.0 - validation acc = 86.0\n",
            "training Finished in 14.229393243789673 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss,validation_loss,train_acc,val_acc=training_loop_(70,model_InRelationship_Bilstm,data_loader_InRelationship_Relatedset,data_loader_InRelationship_Valrelated,criterion,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqDX1LapbZlT",
        "outputId": "7255ead5-9f84-46fd-97e2-228563fa7614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.79       650\n",
            "           1       0.08      0.10      0.09        51\n",
            "           2       0.77      0.69      0.73       524\n",
            "\n",
            "    accuracy                           0.73      1225\n",
            "   macro avg       0.54      0.54      0.54      1225\n",
            "weighted avg       0.74      0.73      0.74      1225\n",
            "\n",
            "Accuracy: 0.733061\n",
            "  \n",
            "Precision:0.539284\n",
            "  \n",
            "Recall: 0.535144\n",
            "  \n",
            "F1 score: 0.535785\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_InRelationship_Bilstm,test_loader_InRelationship_Related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvu7xd_MRbxv"
      },
      "source": [
        "## Specific_comment_Bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Bam8m70zJB0O"
      },
      "outputs": [],
      "source": [
        "embed_size__ = embedding_matrixs_specific.shape[1]\n",
        "vocab_size__ = embedding_matrixs_specific.shape[0]\n",
        "num_classes__ = 3\n",
        "\n",
        "\n",
        "model_Specific_comment_Bilstm  = BiLSTM(vocab_size__, embed_size__, embedding_matrixs_specific,num_classes__,10)\n",
        "\n",
        "\n",
        "model_Specific_comment_Bilstm.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights_specific.values())).float().to(device))\n",
        "optimizer = optim.Adam(model_Specific_comment_Bilstm.parameters(), lr=0.0001, weight_decay=0.000005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4hQCSIRbl3D",
        "outputId": "48229b8a-c7de-4163-ff4a-7a102ce82928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 -  train loss: 1.10563063621521 - validation loss: 1.0978114604949951 - train acc = 0.32625000000000004 - validation acc = 0.35294117647058826\n",
            "epoch: 2 -  train loss: 1.1035977125167846 - validation loss: 1.0977234840393066 - train acc = 0.32375 - validation acc = 0.35294117647058826\n",
            "epoch: 3 -  train loss: 1.1031521558761597 - validation loss: 1.0976746082305908 - train acc = 0.32421875 - validation acc = 0.35294117647058826\n",
            "epoch: 4 -  train loss: 1.1043853282928466 - validation loss: 1.0976344347000122 - train acc = 0.32039062500000004 - validation acc = 0.35294117647058826\n",
            "epoch: 5 -  train loss: 1.1021503686904908 - validation loss: 1.0976194143295288 - train acc = 0.32406250000000003 - validation acc = 0.35294117647058826\n",
            "epoch: 6 -  train loss: 1.1017203330993652 - validation loss: 1.0976122617721558 - train acc = 0.32515625 - validation acc = 0.35294117647058826\n",
            "epoch: 7 -  train loss: 1.10047447681427 - validation loss: 1.0976284742355347 - train acc = 0.330546875 - validation acc = 0.35294117647058826\n",
            "epoch: 8 -  train loss: 1.099654984474182 - validation loss: 1.0976648330688477 - train acc = 0.32632812499999997 - validation acc = 0.35294117647058826\n",
            "epoch: 9 -  train loss: 1.099489188194275 - validation loss: 1.0977177619934082 - train acc = 0.33046875 - validation acc = 0.35294117647058826\n",
            "epoch: 10 -  train loss: 1.0996549129486084 - validation loss: 1.097771406173706 - train acc = 0.32999999999999996 - validation acc = 0.35294117647058826\n",
            "epoch: 11 -  train loss: 1.1000226736068726 - validation loss: 1.0978258848190308 - train acc = 0.3253125 - validation acc = 0.35294117647058826\n",
            "epoch: 12 -  train loss: 1.1001201391220092 - validation loss: 1.0978838205337524 - train acc = 0.32742187500000003 - validation acc = 0.35294117647058826\n",
            "epoch: 13 -  train loss: 1.0987936496734618 - validation loss: 1.0979502201080322 - train acc = 0.32218749999999996 - validation acc = 0.35294117647058826\n",
            "epoch: 14 -  train loss: 1.0995787620544433 - validation loss: 1.0980266332626343 - train acc = 0.340078125 - validation acc = 0.35294117647058826\n",
            "epoch: 15 -  train loss: 1.0988155603408813 - validation loss: 1.0981125831604004 - train acc = 0.33734375 - validation acc = 0.35294117647058826\n",
            "epoch: 16 -  train loss: 1.0982123136520385 - validation loss: 1.0981953144073486 - train acc = 0.340078125 - validation acc = 0.35294117647058826\n",
            "epoch: 17 -  train loss: 1.097626233100891 - validation loss: 1.0982731580734253 - train acc = 0.343359375 - validation acc = 0.35294117647058826\n",
            "epoch: 18 -  train loss: 1.09813232421875 - validation loss: 1.0983589887619019 - train acc = 0.342421875 - validation acc = 0.35294117647058826\n",
            "epoch: 19 -  train loss: 1.0980647325515747 - validation loss: 1.0984406471252441 - train acc = 0.34609375 - validation acc = 0.35294117647058826\n",
            "epoch: 20 -  train loss: 1.098520565032959 - validation loss: 1.0985138416290283 - train acc = 0.33546875 - validation acc = 0.35294117647058826\n",
            "epoch: 21 -  train loss: 1.098140788078308 - validation loss: 1.0986018180847168 - train acc = 0.34890625000000003 - validation acc = 0.35294117647058826\n",
            "epoch: 22 -  train loss: 1.097354030609131 - validation loss: 1.0986909866333008 - train acc = 0.339453125 - validation acc = 0.35294117647058826\n",
            "epoch: 23 -  train loss: 1.096358346939087 - validation loss: 1.0987850427627563 - train acc = 0.35703125 - validation acc = 0.35294117647058826\n",
            "epoch: 24 -  train loss: 1.097137212753296 - validation loss: 1.0988696813583374 - train acc = 0.347421875 - validation acc = 0.35294117647058826\n",
            "epoch: 25 -  train loss: 1.095493197441101 - validation loss: 1.0989456176757812 - train acc = 0.358203125 - validation acc = 0.35294117647058826\n",
            "epoch: 26 -  train loss: 1.0961393356323241 - validation loss: 1.098989725112915 - train acc = 0.35812499999999997 - validation acc = 0.35294117647058826\n",
            "epoch: 27 -  train loss: 1.095701479911804 - validation loss: 1.0990612506866455 - train acc = 0.35281250000000003 - validation acc = 0.35294117647058826\n",
            "epoch: 28 -  train loss: 1.0956420421600341 - validation loss: 1.099120020866394 - train acc = 0.36640625 - validation acc = 0.35294117647058826\n",
            "epoch: 29 -  train loss: 1.0969004392623902 - validation loss: 1.09918212890625 - train acc = 0.348125 - validation acc = 0.35294117647058826\n",
            "epoch: 30 -  train loss: 1.0954926252365111 - validation loss: 1.099249243736267 - train acc = 0.3625 - validation acc = 0.3411764705882353\n",
            "epoch: 31 -  train loss: 1.092771863937378 - validation loss: 1.0993156433105469 - train acc = 0.38828125 - validation acc = 0.35294117647058826\n",
            "epoch: 32 -  train loss: 1.0946900844573975 - validation loss: 1.0993860960006714 - train acc = 0.36398437499999997 - validation acc = 0.36470588235294116\n",
            "epoch: 33 -  train loss: 1.0937135934829711 - validation loss: 1.099446415901184 - train acc = 0.376640625 - validation acc = 0.36470588235294116\n",
            "epoch: 34 -  train loss: 1.093890166282654 - validation loss: 1.099503755569458 - train acc = 0.38289062500000004 - validation acc = 0.3411764705882353\n",
            "epoch: 35 -  train loss: 1.0937411785125732 - validation loss: 1.0995334386825562 - train acc = 0.3828125 - validation acc = 0.32941176470588235\n",
            "epoch: 36 -  train loss: 1.091506791114807 - validation loss: 1.099568486213684 - train acc = 0.39703125 - validation acc = 0.32941176470588235\n",
            "epoch: 37 -  train loss: 1.0925360679626466 - validation loss: 1.0995768308639526 - train acc = 0.393125 - validation acc = 0.32941176470588235\n",
            "epoch: 38 -  train loss: 1.0942272663116455 - validation loss: 1.0996116399765015 - train acc = 0.38109375 - validation acc = 0.3176470588235294\n",
            "epoch: 39 -  train loss: 1.091837739944458 - validation loss: 1.0996441841125488 - train acc = 0.39859374999999997 - validation acc = 0.3058823529411765\n",
            "epoch: 40 -  train loss: 1.090481972694397 - validation loss: 1.0996472835540771 - train acc = 0.410546875 - validation acc = 0.29411764705882354\n",
            "epoch: 41 -  train loss: 1.092417335510254 - validation loss: 1.0996127128601074 - train acc = 0.38687499999999997 - validation acc = 0.29411764705882354\n",
            "epoch: 42 -  train loss: 1.090278434753418 - validation loss: 1.0996054410934448 - train acc = 0.412578125 - validation acc = 0.29411764705882354\n",
            "epoch: 43 -  train loss: 1.0906801223754883 - validation loss: 1.0996270179748535 - train acc = 0.41 - validation acc = 0.29411764705882354\n",
            "epoch: 44 -  train loss: 1.0903529405593873 - validation loss: 1.099628210067749 - train acc = 0.40421874999999996 - validation acc = 0.3058823529411765\n",
            "epoch: 45 -  train loss: 1.0908434391021729 - validation loss: 1.0996400117874146 - train acc = 0.40992187500000005 - validation acc = 0.3176470588235294\n",
            "epoch: 46 -  train loss: 1.0891808032989503 - validation loss: 1.0996261835098267 - train acc = 0.41429687499999995 - validation acc = 0.3176470588235294\n",
            "epoch: 47 -  train loss: 1.0887181043624878 - validation loss: 1.099646806716919 - train acc = 0.42265625 - validation acc = 0.32941176470588235\n",
            "epoch: 48 -  train loss: 1.0895553588867188 - validation loss: 1.0996216535568237 - train acc = 0.424453125 - validation acc = 0.3176470588235294\n",
            "epoch: 49 -  train loss: 1.0879918575286864 - validation loss: 1.0995912551879883 - train acc = 0.423984375 - validation acc = 0.3176470588235294\n",
            "epoch: 50 -  train loss: 1.0870414972305298 - validation loss: 1.099529504776001 - train acc = 0.43562500000000004 - validation acc = 0.3176470588235294\n",
            "epoch: 51 -  train loss: 1.0859479427337646 - validation loss: 1.0995081663131714 - train acc = 0.43921875000000005 - validation acc = 0.3058823529411765\n",
            "epoch: 52 -  train loss: 1.0869022846221923 - validation loss: 1.099477767944336 - train acc = 0.430859375 - validation acc = 0.3176470588235294\n",
            "epoch: 53 -  train loss: 1.086072063446045 - validation loss: 1.0994559526443481 - train acc = 0.438984375 - validation acc = 0.3176470588235294\n",
            "epoch: 54 -  train loss: 1.0838539123535156 - validation loss: 1.099400520324707 - train acc = 0.46851562500000005 - validation acc = 0.3176470588235294\n",
            "epoch: 55 -  train loss: 1.0835873126983642 - validation loss: 1.099381446838379 - train acc = 0.4646875 - validation acc = 0.3176470588235294\n",
            "epoch: 56 -  train loss: 1.0851417779922485 - validation loss: 1.0993366241455078 - train acc = 0.45359375 - validation acc = 0.3176470588235294\n",
            "epoch: 57 -  train loss: 1.0838258028030396 - validation loss: 1.0993047952651978 - train acc = 0.460546875 - validation acc = 0.3058823529411765\n",
            "epoch: 58 -  train loss: 1.0818537712097167 - validation loss: 1.099233865737915 - train acc = 0.46929687500000006 - validation acc = 0.3176470588235294\n",
            "epoch: 59 -  train loss: 1.084484338760376 - validation loss: 1.0991291999816895 - train acc = 0.454765625 - validation acc = 0.3176470588235294\n",
            "epoch: 60 -  train loss: 1.0810673475265502 - validation loss: 1.0990233421325684 - train acc = 0.4640625 - validation acc = 0.3176470588235294\n",
            "epoch: 61 -  train loss: 1.081566858291626 - validation loss: 1.0989245176315308 - train acc = 0.46015625 - validation acc = 0.3176470588235294\n",
            "epoch: 62 -  train loss: 1.0813543319702148 - validation loss: 1.098854422569275 - train acc = 0.46585937499999996 - validation acc = 0.3176470588235294\n",
            "epoch: 63 -  train loss: 1.0789746522903443 - validation loss: 1.0987473726272583 - train acc = 0.484765625 - validation acc = 0.3176470588235294\n",
            "epoch: 64 -  train loss: 1.0768149614334106 - validation loss: 1.0986638069152832 - train acc = 0.4953125 - validation acc = 0.3176470588235294\n",
            "epoch: 65 -  train loss: 1.0760273694992066 - validation loss: 1.0987035036087036 - train acc = 0.49898437500000004 - validation acc = 0.3176470588235294\n",
            "epoch: 66 -  train loss: 1.0759919166564942 - validation loss: 1.0986809730529785 - train acc = 0.5015625 - validation acc = 0.3176470588235294\n",
            "epoch: 67 -  train loss: 1.075070333480835 - validation loss: 1.0985928773880005 - train acc = 0.512734375 - validation acc = 0.3176470588235294\n",
            "epoch: 68 -  train loss: 1.0752279996871947 - validation loss: 1.098494529724121 - train acc = 0.5053124999999999 - validation acc = 0.3176470588235294\n",
            "epoch: 69 -  train loss: 1.0716855764389037 - validation loss: 1.0984665155410767 - train acc = 0.5275000000000001 - validation acc = 0.3176470588235294\n",
            "epoch: 70 -  train loss: 1.0711389541625977 - validation loss: 1.0984373092651367 - train acc = 0.53640625 - validation acc = 0.32941176470588235\n",
            "epoch: 71 -  train loss: 1.071728730201721 - validation loss: 1.0984309911727905 - train acc = 0.5213281249999999 - validation acc = 0.32941176470588235\n",
            "epoch: 72 -  train loss: 1.068602728843689 - validation loss: 1.09836745262146 - train acc = 0.5411718750000001 - validation acc = 0.32941176470588235\n",
            "epoch: 73 -  train loss: 1.0679710865020753 - validation loss: 1.0982437133789062 - train acc = 0.5348437500000001 - validation acc = 0.32941176470588235\n",
            "epoch: 74 -  train loss: 1.0671519994735719 - validation loss: 1.0981642007827759 - train acc = 0.550859375 - validation acc = 0.32941176470588235\n",
            "epoch: 75 -  train loss: 1.0659303426742555 - validation loss: 1.0981062650680542 - train acc = 0.53734375 - validation acc = 0.32941176470588235\n",
            "epoch: 76 -  train loss: 1.0624037504196167 - validation loss: 1.0980429649353027 - train acc = 0.561640625 - validation acc = 0.32941176470588235\n",
            "epoch: 77 -  train loss: 1.0639517784118653 - validation loss: 1.0979746580123901 - train acc = 0.542109375 - validation acc = 0.3411764705882353\n",
            "epoch: 78 -  train loss: 1.0604098796844483 - validation loss: 1.097946047782898 - train acc = 0.55234375 - validation acc = 0.3411764705882353\n",
            "epoch: 79 -  train loss: 1.059743618965149 - validation loss: 1.0978920459747314 - train acc = 0.5721875 - validation acc = 0.3411764705882353\n",
            "epoch: 80 -  train loss: 1.0600083589553833 - validation loss: 1.0977904796600342 - train acc = 0.5540625 - validation acc = 0.32941176470588235\n",
            "epoch: 81 -  train loss: 1.0551671743392945 - validation loss: 1.0975857973098755 - train acc = 0.575078125 - validation acc = 0.32941176470588235\n",
            "epoch: 82 -  train loss: 1.0552922248840333 - validation loss: 1.0974903106689453 - train acc = 0.5680468750000001 - validation acc = 0.32941176470588235\n",
            "epoch: 83 -  train loss: 1.0503770351409911 - validation loss: 1.0973081588745117 - train acc = 0.587890625 - validation acc = 0.32941176470588235\n",
            "epoch: 84 -  train loss: 1.0499508857727051 - validation loss: 1.0971591472625732 - train acc = 0.6038281249999999 - validation acc = 0.32941176470588235\n",
            "epoch: 85 -  train loss: 1.0473721504211426 - validation loss: 1.09695565700531 - train acc = 0.612578125 - validation acc = 0.32941176470588235\n",
            "epoch: 86 -  train loss: 1.0449490547180176 - validation loss: 1.0968220233917236 - train acc = 0.5825781250000001 - validation acc = 0.32941176470588235\n",
            "epoch: 87 -  train loss: 1.043514037132263 - validation loss: 1.096630334854126 - train acc = 0.59828125 - validation acc = 0.32941176470588235\n",
            "epoch: 88 -  train loss: 1.0410109281539917 - validation loss: 1.0964161157608032 - train acc = 0.60703125 - validation acc = 0.32941176470588235\n",
            "epoch: 89 -  train loss: 1.0362066984176637 - validation loss: 1.0961910486221313 - train acc = 0.629609375 - validation acc = 0.32941176470588235\n",
            "epoch: 90 -  train loss: 1.0348144054412842 - validation loss: 1.0959852933883667 - train acc = 0.635625 - validation acc = 0.32941176470588235\n",
            "epoch: 91 -  train loss: 1.0328055620193481 - validation loss: 1.0957672595977783 - train acc = 0.620703125 - validation acc = 0.32941176470588235\n",
            "epoch: 92 -  train loss: 1.0315134286880494 - validation loss: 1.0955685377120972 - train acc = 0.63875 - validation acc = 0.3411764705882353\n",
            "epoch: 93 -  train loss: 1.0288976907730103 - validation loss: 1.0953333377838135 - train acc = 0.6422656250000001 - validation acc = 0.32941176470588235\n",
            "epoch: 94 -  train loss: 1.0254014730453491 - validation loss: 1.095076560974121 - train acc = 0.6467968749999999 - validation acc = 0.3411764705882353\n",
            "epoch: 95 -  train loss: 1.019577145576477 - validation loss: 1.0948227643966675 - train acc = 0.63984375 - validation acc = 0.32941176470588235\n",
            "epoch: 96 -  train loss: 1.0153398036956787 - validation loss: 1.0946896076202393 - train acc = 0.668359375 - validation acc = 0.32941176470588235\n",
            "epoch: 97 -  train loss: 1.0137892961502075 - validation loss: 1.0946497917175293 - train acc = 0.65859375 - validation acc = 0.32941176470588235\n",
            "epoch: 98 -  train loss: 1.0102942943573 - validation loss: 1.0946602821350098 - train acc = 0.6599999999999999 - validation acc = 0.3176470588235294\n",
            "epoch: 99 -  train loss: 1.0094957113265992 - validation loss: 1.0944652557373047 - train acc = 0.6704687500000001 - validation acc = 0.32941176470588235\n",
            "epoch: 100 -  train loss: 1.003340196609497 - validation loss: 1.0942484140396118 - train acc = 0.68203125 - validation acc = 0.3411764705882353\n",
            "epoch: 101 -  train loss: 0.9996262311935424 - validation loss: 1.0940552949905396 - train acc = 0.684375 - validation acc = 0.35294117647058826\n",
            "epoch: 102 -  train loss: 0.9941363096237182 - validation loss: 1.0939323902130127 - train acc = 0.68703125 - validation acc = 0.3411764705882353\n",
            "epoch: 103 -  train loss: 0.9928688883781434 - validation loss: 1.0937421321868896 - train acc = 0.6780468749999999 - validation acc = 0.32941176470588235\n",
            "epoch: 104 -  train loss: 0.9869688987731934 - validation loss: 1.0936256647109985 - train acc = 0.678359375 - validation acc = 0.32941176470588235\n",
            "epoch: 105 -  train loss: 0.9832301139831543 - validation loss: 1.0934487581253052 - train acc = 0.706953125 - validation acc = 0.3411764705882353\n",
            "epoch: 106 -  train loss: 0.978861141204834 - validation loss: 1.0931776762008667 - train acc = 0.695390625 - validation acc = 0.35294117647058826\n",
            "epoch: 107 -  train loss: 0.9715330600738525 - validation loss: 1.0928432941436768 - train acc = 0.706171875 - validation acc = 0.36470588235294116\n",
            "epoch: 108 -  train loss: 0.9708441019058227 - validation loss: 1.0926867723464966 - train acc = 0.71015625 - validation acc = 0.36470588235294116\n",
            "epoch: 109 -  train loss: 0.9619533538818359 - validation loss: 1.0924674272537231 - train acc = 0.718671875 - validation acc = 0.3764705882352941\n",
            "epoch: 110 -  train loss: 0.9600717186927795 - validation loss: 1.0922443866729736 - train acc = 0.708984375 - validation acc = 0.3764705882352941\n",
            "epoch: 111 -  train loss: 0.9563162326812744 - validation loss: 1.0920249223709106 - train acc = 0.714921875 - validation acc = 0.38823529411764707\n",
            "epoch: 112 -  train loss: 0.9471830248832702 - validation loss: 1.0918676853179932 - train acc = 0.738515625 - validation acc = 0.38823529411764707\n",
            "epoch: 113 -  train loss: 0.9426369786262512 - validation loss: 1.0916237831115723 - train acc = 0.721640625 - validation acc = 0.38823529411764707\n",
            "epoch: 114 -  train loss: 0.9329008460044861 - validation loss: 1.091438889503479 - train acc = 0.7424999999999999 - validation acc = 0.3764705882352941\n",
            "epoch: 115 -  train loss: 0.9293301105499268 - validation loss: 1.0911961793899536 - train acc = 0.7365625 - validation acc = 0.3764705882352941\n",
            "epoch: 116 -  train loss: 0.9212758660316467 - validation loss: 1.0906695127487183 - train acc = 0.7407812500000001 - validation acc = 0.38823529411764707\n",
            "epoch: 117 -  train loss: 0.9176257967948913 - validation loss: 1.090443730354309 - train acc = 0.742421875 - validation acc = 0.3764705882352941\n",
            "epoch: 118 -  train loss: 0.9094163298606872 - validation loss: 1.0905332565307617 - train acc = 0.7494531249999999 - validation acc = 0.3764705882352941\n",
            "epoch: 119 -  train loss: 0.9020442605018616 - validation loss: 1.0904040336608887 - train acc = 0.7716406250000001 - validation acc = 0.3764705882352941\n",
            "epoch: 120 -  train loss: 0.8960313439369202 - validation loss: 1.0900979042053223 - train acc = 0.7540625000000001 - validation acc = 0.3764705882352941\n",
            "epoch: 121 -  train loss: 0.8887960076332092 - validation loss: 1.089746117591858 - train acc = 0.7725 - validation acc = 0.3764705882352941\n",
            "epoch: 122 -  train loss: 0.8824357509613037 - validation loss: 1.0898891687393188 - train acc = 0.7678125 - validation acc = 0.3764705882352941\n",
            "epoch: 123 -  train loss: 0.8748568177223206 - validation loss: 1.0897167921066284 - train acc = 0.766484375 - validation acc = 0.38823529411764707\n",
            "epoch: 124 -  train loss: 0.8640776395797729 - validation loss: 1.089479684829712 - train acc = 0.78328125 - validation acc = 0.38823529411764707\n",
            "epoch: 125 -  train loss: 0.8590490698814393 - validation loss: 1.0891566276550293 - train acc = 0.7833593750000001 - validation acc = 0.38823529411764707\n",
            "epoch: 126 -  train loss: 0.8497060775756836 - validation loss: 1.0888018608093262 - train acc = 0.78671875 - validation acc = 0.38823529411764707\n",
            "epoch: 127 -  train loss: 0.8459169030189514 - validation loss: 1.0888959169387817 - train acc = 0.777734375 - validation acc = 0.4\n",
            "epoch: 128 -  train loss: 0.8377614140510559 - validation loss: 1.088901400566101 - train acc = 0.802109375 - validation acc = 0.4\n",
            "epoch: 129 -  train loss: 0.8237223267555237 - validation loss: 1.0887701511383057 - train acc = 0.7970312500000001 - validation acc = 0.4117647058823529\n",
            "epoch: 130 -  train loss: 0.8148375272750854 - validation loss: 1.0884987115859985 - train acc = 0.812265625 - validation acc = 0.4117647058823529\n",
            "epoch: 131 -  train loss: 0.8090705633163452 - validation loss: 1.0879733562469482 - train acc = 0.8016406249999999 - validation acc = 0.4117647058823529\n",
            "epoch: 132 -  train loss: 0.801590621471405 - validation loss: 1.087357997894287 - train acc = 0.802734375 - validation acc = 0.4\n",
            "epoch: 133 -  train loss: 0.7867850542068482 - validation loss: 1.0870777368545532 - train acc = 0.821015625 - validation acc = 0.4117647058823529\n",
            "epoch: 134 -  train loss: 0.7838682770729065 - validation loss: 1.0870623588562012 - train acc = 0.8237500000000001 - validation acc = 0.4235294117647059\n",
            "epoch: 135 -  train loss: 0.7722690105438232 - validation loss: 1.0875825881958008 - train acc = 0.819296875 - validation acc = 0.4\n",
            "epoch: 136 -  train loss: 0.7549960255622864 - validation loss: 1.0877026319503784 - train acc = 0.821640625 - validation acc = 0.4\n",
            "epoch: 137 -  train loss: 0.7527790069580078 - validation loss: 1.0878602266311646 - train acc = 0.8270312499999999 - validation acc = 0.4\n",
            "epoch: 138 -  train loss: 0.7431622982025147 - validation loss: 1.0874680280685425 - train acc = 0.8353125 - validation acc = 0.4\n",
            "epoch: 139 -  train loss: 0.731770646572113 - validation loss: 1.0875771045684814 - train acc = 0.83375 - validation acc = 0.4\n",
            "epoch: 140 -  train loss: 0.7240942358970642 - validation loss: 1.0875537395477295 - train acc = 0.8439062500000001 - validation acc = 0.4\n",
            "epoch: 141 -  train loss: 0.7128141641616821 - validation loss: 1.0876266956329346 - train acc = 0.8358593750000001 - validation acc = 0.4\n",
            "epoch: 142 -  train loss: 0.6953110456466675 - validation loss: 1.0877556800842285 - train acc = 0.851796875 - validation acc = 0.4\n",
            "epoch: 143 -  train loss: 0.6875081419944763 - validation loss: 1.0884978771209717 - train acc = 0.845390625 - validation acc = 0.4\n",
            "epoch: 144 -  train loss: 0.6807240009307861 - validation loss: 1.0881309509277344 - train acc = 0.8428906250000001 - validation acc = 0.4\n",
            "epoch: 145 -  train loss: 0.6714988350868225 - validation loss: 1.088262915611267 - train acc = 0.8467968750000001 - validation acc = 0.4\n",
            "epoch: 146 -  train loss: 0.6657032012939453 - validation loss: 1.0888211727142334 - train acc = 0.8495312500000001 - validation acc = 0.4\n",
            "epoch: 147 -  train loss: 0.6463815569877625 - validation loss: 1.0896426439285278 - train acc = 0.850546875 - validation acc = 0.38823529411764707\n",
            "epoch: 148 -  train loss: 0.6377248644828797 - validation loss: 1.0899380445480347 - train acc = 0.863671875 - validation acc = 0.4117647058823529\n",
            "epoch: 149 -  train loss: 0.6359156489372253 - validation loss: 1.0905709266662598 - train acc = 0.8516406249999999 - validation acc = 0.4\n",
            "epoch: 150 -  train loss: 0.6221247553825379 - validation loss: 1.0910229682922363 - train acc = 0.8596875 - validation acc = 0.4235294117647059\n",
            "training Finished in 14.744261264801025 seconds\n"
          ]
        }
      ],
      "source": [
        "train_loss_,validation_loss_,train_acc_,val_acc_=training_loop(150,model_Specific_comment_Bilstm,data_loader_Specific_set,data_loader_Valspecific,criterion,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtfH79A0bohC",
        "outputId": "27d37119-3cbc-476f-fa97-7a399028a817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.55      0.50       171\n",
            "           1       0.40      0.33      0.36       181\n",
            "           2       0.42      0.42      0.42       195\n",
            "\n",
            "    accuracy                           0.43       547\n",
            "   macro avg       0.43      0.43      0.43       547\n",
            "weighted avg       0.43      0.43      0.43       547\n",
            "\n",
            "Accuracy: 0.429616\n",
            "  \n",
            "Precision:0.426886\n",
            "  \n",
            "Recall: 0.432062\n",
            "  \n",
            "F1 score: 0.426932\n"
          ]
        }
      ],
      "source": [
        "Evaluate(model_Specific_comment_Bilstm,test_loader_Specific)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
